{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "19955fedf5d7489aa3f663408fa1d10f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31067848adaf41d986a46af9adbd4720",
              "IPY_MODEL_906e474cd2dc41f9a42b30f5d6e7778e",
              "IPY_MODEL_d9b954d615924aacb387e35149f5f4cd"
            ],
            "layout": "IPY_MODEL_baa305e446274e088f3d39894aa5aa56"
          }
        },
        "31067848adaf41d986a46af9adbd4720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eef13210fec04652a720c5ec17a34c51",
            "placeholder": "​",
            "style": "IPY_MODEL_a0246de425e94f9ea61a13d44dc2cc96",
            "value": "tokenizer.json: 100%"
          }
        },
        "906e474cd2dc41f9a42b30f5d6e7778e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07926471ac7a4bc6a18fa5789f568890",
            "max": 2825034,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8132215224dd4d429be02bcbf6401b5d",
            "value": 2825034
          }
        },
        "d9b954d615924aacb387e35149f5f4cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f50d4bc6382427d986803d7cfff0cc6",
            "placeholder": "​",
            "style": "IPY_MODEL_12c3e271d869478cafaf9ef1db5dd246",
            "value": " 2.83M/2.83M [00:00&lt;00:00, 12.3MB/s]"
          }
        },
        "baa305e446274e088f3d39894aa5aa56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eef13210fec04652a720c5ec17a34c51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0246de425e94f9ea61a13d44dc2cc96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07926471ac7a4bc6a18fa5789f568890": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8132215224dd4d429be02bcbf6401b5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f50d4bc6382427d986803d7cfff0cc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12c3e271d869478cafaf9ef1db5dd246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8063bd4f80834944a5ccf8af2c359cb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e613ff02e0fb48f3842a8c228d247a1d",
              "IPY_MODEL_e8b0c2767268497488139da87454400e",
              "IPY_MODEL_be6b94def0d34b5491ac9804f22222ee"
            ],
            "layout": "IPY_MODEL_2d1fd05024b0420bac1db1251520e194"
          }
        },
        "e613ff02e0fb48f3842a8c228d247a1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9a5f201843b4b398a6ff5dd9218aad2",
            "placeholder": "​",
            "style": "IPY_MODEL_9b61a4022bf44073a752b9bba1fdf703",
            "value": "config.json: 100%"
          }
        },
        "e8b0c2767268497488139da87454400e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c31f2e6f5649414299885c257d3b9e73",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1969435b7072408ebc29e9a6678a8b7c",
            "value": 1000
          }
        },
        "be6b94def0d34b5491ac9804f22222ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b04d01658b3e49dcb5cb53024338b412",
            "placeholder": "​",
            "style": "IPY_MODEL_2058ffb6a31b4966bb84bb293b8072ff",
            "value": " 1.00k/1.00k [00:00&lt;00:00, 85.5kB/s]"
          }
        },
        "2d1fd05024b0420bac1db1251520e194": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9a5f201843b4b398a6ff5dd9218aad2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b61a4022bf44073a752b9bba1fdf703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c31f2e6f5649414299885c257d3b9e73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1969435b7072408ebc29e9a6678a8b7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b04d01658b3e49dcb5cb53024338b412": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2058ffb6a31b4966bb84bb293b8072ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d74d88d520b44f359c2b59034480c7fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3afe4381d56a487da1c6c058ad8f4f53",
              "IPY_MODEL_7769edb6127640cdaef11f562783f86c",
              "IPY_MODEL_6f56eae95dda4547ab749c9a36c7596b"
            ],
            "layout": "IPY_MODEL_2de688ab82e649d79e77ff4564ec7385"
          }
        },
        "3afe4381d56a487da1c6c058ad8f4f53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a3d20ad2a89449098dcf49b3cf6b7c3",
            "placeholder": "​",
            "style": "IPY_MODEL_cc4bfaa38cf643c48fc1be616da8e7cb",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "7769edb6127640cdaef11f562783f86c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae682ef9ac734ebb885441cb62316709",
            "max": 513302779,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_810606cd19bc4b2fbe909a097c0ffc8b",
            "value": 513302779
          }
        },
        "6f56eae95dda4547ab749c9a36c7596b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7600ee991334bcb84727ca737e9f544",
            "placeholder": "​",
            "style": "IPY_MODEL_7d2d3638f7e54b0ab9d5b553bbc11462",
            "value": " 513M/513M [00:02&lt;00:00, 214MB/s]"
          }
        },
        "2de688ab82e649d79e77ff4564ec7385": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a3d20ad2a89449098dcf49b3cf6b7c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc4bfaa38cf643c48fc1be616da8e7cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae682ef9ac734ebb885441cb62316709": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "810606cd19bc4b2fbe909a097c0ffc8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7600ee991334bcb84727ca737e9f544": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d2d3638f7e54b0ab9d5b553bbc11462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 직접 작성 (GPT2LMHeadModel)"
      ],
      "metadata": {
        "id": "RKM97yfJ2ews"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_lightning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtIMytbNbw-l",
        "outputId": "a8c66451-43bd-4689-f981-e3f082046d42"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-2.2.5-py3-none-any.whl (802 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/802.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.8/802.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m573.4/802.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.3/802.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2.3.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.66.4)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch_lightning)\n",
            "  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (24.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.11.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from pytorch_lightning)\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch_lightning) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->pytorch_lightning)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->pytorch_lightning) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->pytorch_lightning) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch_lightning\n",
            "Successfully installed lightning-utilities-0.11.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pytorch_lightning-2.2.5 torchmetrics-1.4.0.post0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 불러오기\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.core import LightningModule\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n",
        "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n",
        "import re, os\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "tIMe8fSB2maC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "os.environ[\"TORCH_USE_CUDA_DSA\"] = '1'"
      ],
      "metadata": {
        "id": "jxraN86XqMfs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼 파라메터 설정\n",
        "Q_TKN = \"<usr>\"\n",
        "A_TKN = \"<sys>\"\n",
        "BOS = \"</s>\"\n",
        "EOS = \"</s>\"\n",
        "MASK = \"<unused0>\"\n",
        "SENT = \"<unused1>\"\n",
        "PAD = \"<pad>\"\n",
        "EPOCHS = 5\n",
        "Sneg = -1e18\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "learning_rate=3e-5"
      ],
      "metadata": {
        "id": "OGtbi6fA2_15"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 토크나이저 불러오기\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
        "                                                    bos_token=BOS,\n",
        "                                                    eos_token=EOS,\n",
        "                                                    unk_token='<unk>',\n",
        "                                                    pad_token=PAD,\n",
        "                                                    mask_token=MASK)\n",
        "\n",
        "# 모델 불러오기\n",
        "model = GPT2LMHeadModel.from_pretrained(\"skt/kogpt2-base-v2\")\n",
        "\n",
        "# 데이터셋 가져오기\n",
        "data_url = \"https://raw.githubusercontent.com/IDIOcoder/Chat-bot/main/dataset/answer_dataset.csv\"\n",
        "data_set = pd.read_csv(data_url, encoding='utf-8')\n",
        "data_set.dropna(subset=[\"Q\"], inplace=True)\n",
        "data_set.dropna(subset=[\"A\"], inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324,
          "referenced_widgets": [
            "19955fedf5d7489aa3f663408fa1d10f",
            "31067848adaf41d986a46af9adbd4720",
            "906e474cd2dc41f9a42b30f5d6e7778e",
            "d9b954d615924aacb387e35149f5f4cd",
            "baa305e446274e088f3d39894aa5aa56",
            "eef13210fec04652a720c5ec17a34c51",
            "a0246de425e94f9ea61a13d44dc2cc96",
            "07926471ac7a4bc6a18fa5789f568890",
            "8132215224dd4d429be02bcbf6401b5d",
            "5f50d4bc6382427d986803d7cfff0cc6",
            "12c3e271d869478cafaf9ef1db5dd246",
            "8063bd4f80834944a5ccf8af2c359cb3",
            "e613ff02e0fb48f3842a8c228d247a1d",
            "e8b0c2767268497488139da87454400e",
            "be6b94def0d34b5491ac9804f22222ee",
            "2d1fd05024b0420bac1db1251520e194",
            "f9a5f201843b4b398a6ff5dd9218aad2",
            "9b61a4022bf44073a752b9bba1fdf703",
            "c31f2e6f5649414299885c257d3b9e73",
            "1969435b7072408ebc29e9a6678a8b7c",
            "b04d01658b3e49dcb5cb53024338b412",
            "2058ffb6a31b4966bb84bb293b8072ff",
            "d74d88d520b44f359c2b59034480c7fd",
            "3afe4381d56a487da1c6c058ad8f4f53",
            "7769edb6127640cdaef11f562783f86c",
            "6f56eae95dda4547ab749c9a36c7596b",
            "2de688ab82e649d79e77ff4564ec7385",
            "2a3d20ad2a89449098dcf49b3cf6b7c3",
            "cc4bfaa38cf643c48fc1be616da8e7cb",
            "ae682ef9ac734ebb885441cb62316709",
            "810606cd19bc4b2fbe909a097c0ffc8b",
            "b7600ee991334bcb84727ca737e9f544",
            "7d2d3638f7e54b0ab9d5b553bbc11462"
          ]
        },
        "id": "mLqC54Zy4cRo",
        "outputId": "14e3130b-3e3c-4ad2-c86c-7d6d31119f04"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.83M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "19955fedf5d7489aa3f663408fa1d10f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8063bd4f80834944a5ccf8af2c359cb3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/513M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d74d88d520b44f359c2b59034480c7fd"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_set.head(-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "k20lqTNzojBd",
        "outputId": "9adfbab6-db09-4dfa-8fbd-a0a96af8d1c6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                      Q  \\\n",
              "0     이번 프로젝트에서 발표를 하는데 내가 실수하는 바람에 우리 팀이 감점을 받았어. 너...   \n",
              "1                 회사에서 중요한 프로젝트를 혼자 하게 됐는데 솔직히 두렵고 무서워.   \n",
              "2             이번에 힘들게 들어간 첫 직장이거든. 첫 직장이라서 그런지 너무 긴장된다.   \n",
              "3                           대회에 나갔는데 예전의 내 기록을 훨씬 갱신했어!   \n",
              "4                  150만 원짜리 노트북을 샀는데 오늘 배송돼서 기분이 너무 좋아!   \n",
              "...                                                 ...   \n",
              "3830  어떡해! 내일 시험인데 공부를 전혀 안 했어. 어젯밤에 그냥 잠들어버렸어. 시험지 ...   \n",
              "3831  완전 난리 났어! 이번 시험 공부를 하나도 안 했어. 친구들은 다 공부했을 텐데, ...   \n",
              "3832  이번 시험 정말 큰일 났어! 공부를 하려고 했는데, 결국은 그냥 놀기만 했어. 시험...   \n",
              "3833  헉! 내일 시험인데 공부를 하나도 못 했어. 어제 밤에 잠들어버려서 오늘 하루 종일...   \n",
              "3834  어쩌면 좋아! 시험 준비를 전혀 안 했어. 다른 친구들은 다 열심히 공부했을 텐데,...   \n",
              "\n",
              "                                                      A  구분  \n",
              "0     그런 일이 있었군요. 실수는 누구에게나 일어날 수 있는 일이에요. 중요한 건 그것을...  대화  \n",
              "1     프로젝트를 혼자 맡는 것은 정말 큰 도전일 테지만, 동시에 많은 성장의 기회가 될 ...  대화  \n",
              "2     첫 직장은 항상 긴장되고 설레는 시간이죠. 새로운 환경에서 적응하는 것은 어려운 일...  대화  \n",
              "3     대단하시네요! 축하드립니다! 실력을 계속 향상시키고 성취를 이루는 건 정말 멋진 일...  대화  \n",
              "4     축하해요! 새로운 노트북으로 더 많은 일들을 해나가실 거예요. 새로운 도구로 무엇을...  대화  \n",
              "...                                                 ...  ..  \n",
              "3830  걱정이 많으시겠어요. 지금이라도 조금이라도 공부해보세요. 시험 전에는 긴장하지 않고...  대화  \n",
              "3831  불안해하시는 마음 이해해요. 지금이라도 조금이라도 공부해보세요. 시험 전에는 긴장하...  대화  \n",
              "3832  놀기만 해서 걱정이시겠어요. 지금이라도 조금이라도 공부해보세요. 시험 전에는 긴장하...  대화  \n",
              "3833  걱정이 많으시겠어요. 지금이라도 조금이라도 공부해보세요. 시험 전에는 긴장하지 않고...  대화  \n",
              "3834  걱정이 많으시겠어요. 지금이라도 조금이라도 공부해보세요. 시험 전에는 긴장하지 않고...  대화  \n",
              "\n",
              "[3835 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b449c9db-1338-48e1-bda1-5c722f8fd18b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>구분</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>이번 프로젝트에서 발표를 하는데 내가 실수하는 바람에 우리 팀이 감점을 받았어. 너...</td>\n",
              "      <td>그런 일이 있었군요. 실수는 누구에게나 일어날 수 있는 일이에요. 중요한 건 그것을...</td>\n",
              "      <td>대화</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>회사에서 중요한 프로젝트를 혼자 하게 됐는데 솔직히 두렵고 무서워.</td>\n",
              "      <td>프로젝트를 혼자 맡는 것은 정말 큰 도전일 테지만, 동시에 많은 성장의 기회가 될 ...</td>\n",
              "      <td>대화</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>이번에 힘들게 들어간 첫 직장이거든. 첫 직장이라서 그런지 너무 긴장된다.</td>\n",
              "      <td>첫 직장은 항상 긴장되고 설레는 시간이죠. 새로운 환경에서 적응하는 것은 어려운 일...</td>\n",
              "      <td>대화</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>대회에 나갔는데 예전의 내 기록을 훨씬 갱신했어!</td>\n",
              "      <td>대단하시네요! 축하드립니다! 실력을 계속 향상시키고 성취를 이루는 건 정말 멋진 일...</td>\n",
              "      <td>대화</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>150만 원짜리 노트북을 샀는데 오늘 배송돼서 기분이 너무 좋아!</td>\n",
              "      <td>축하해요! 새로운 노트북으로 더 많은 일들을 해나가실 거예요. 새로운 도구로 무엇을...</td>\n",
              "      <td>대화</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3830</th>\n",
              "      <td>어떡해! 내일 시험인데 공부를 전혀 안 했어. 어젯밤에 그냥 잠들어버렸어. 시험지 ...</td>\n",
              "      <td>걱정이 많으시겠어요. 지금이라도 조금이라도 공부해보세요. 시험 전에는 긴장하지 않고...</td>\n",
              "      <td>대화</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3831</th>\n",
              "      <td>완전 난리 났어! 이번 시험 공부를 하나도 안 했어. 친구들은 다 공부했을 텐데, ...</td>\n",
              "      <td>불안해하시는 마음 이해해요. 지금이라도 조금이라도 공부해보세요. 시험 전에는 긴장하...</td>\n",
              "      <td>대화</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3832</th>\n",
              "      <td>이번 시험 정말 큰일 났어! 공부를 하려고 했는데, 결국은 그냥 놀기만 했어. 시험...</td>\n",
              "      <td>놀기만 해서 걱정이시겠어요. 지금이라도 조금이라도 공부해보세요. 시험 전에는 긴장하...</td>\n",
              "      <td>대화</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3833</th>\n",
              "      <td>헉! 내일 시험인데 공부를 하나도 못 했어. 어제 밤에 잠들어버려서 오늘 하루 종일...</td>\n",
              "      <td>걱정이 많으시겠어요. 지금이라도 조금이라도 공부해보세요. 시험 전에는 긴장하지 않고...</td>\n",
              "      <td>대화</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3834</th>\n",
              "      <td>어쩌면 좋아! 시험 준비를 전혀 안 했어. 다른 친구들은 다 열심히 공부했을 텐데,...</td>\n",
              "      <td>걱정이 많으시겠어요. 지금이라도 조금이라도 공부해보세요. 시험 전에는 긴장하지 않고...</td>\n",
              "      <td>대화</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3835 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b449c9db-1338-48e1-bda1-5c722f8fd18b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b449c9db-1338-48e1-bda1-5c722f8fd18b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b449c9db-1338-48e1-bda1-5c722f8fd18b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d15d367b-faf6-4bb0-9043-1f84c508942b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d15d367b-faf6-4bb0-9043-1f84c508942b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d15d367b-faf6-4bb0-9043-1f84c508942b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_set",
              "summary": "{\n  \"name\": \"data_set\",\n  \"rows\": 3836,\n  \"fields\": [\n    {\n      \"column\": \"Q\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3503,\n        \"samples\": [\n          \"\\uadf8 \\uc0ac\\ub78c\\uc774 \\ub098\\ub97c \\uc5b4\\ub5bb\\uac8c \\uc0dd\\uac01\\ud558\\ub294\\uc9c0 \\uc54c \\uc218 \\uc5c6\\uc5b4\\uc11c \\uad34\\ub85c\\uc6cc.\",\n          \"\\uc81c \\uc5f0\\uc778\\uacfc \\ub9ce\\uc774 \\uc2f8\\uc6cc\\uc11c \\ud798\\ub4e4\\uc5b4\\uc694.\",\n          \"\\uc5b4\\uc81c \\ubc24\\uc0c8\\uc11c \\uc791\\uc5c5\\ud588\\ub294\\ub370 \\ub4dc\\ub514\\uc5b4 \\ub05d\\ub0ac\\uc5b4! \\ub108\\ubb34 \\ubfcc\\ub4ef\\ud574.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"A\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3553,\n        \"samples\": [\n          \"\\uc5c5\\ubb34 \\uc555\\ubc15\\uc744 \\ub290\\ub07c\\uc2e0\\ub2e4\\uba74, \\uc77c\\uc744 \\uc7a0\\uc2dc \\uba48\\ucd94\\uace0 \\uc9e7\\uc740 \\uc0b0\\ucc45\\uc774\\ub098 \\uba85\\uc0c1 \\uc2dc\\uac04\\uc744 \\uac00\\uc838\\ubcf4\\uc138\\uc694. \\uadf8\\ub9ac\\uace0 \\uc5c5\\ubb34 \\ud6c4\\uc5d0\\ub294 \\uc790\\uc2e0\\uc744 \\uc704\\ud55c \\ud2b9\\ubcc4\\ud55c \\uc800\\ub141\\uc744 \\uc900\\ube44\\ud574\\ubcf4\\ub294 \\uac74 \\uc5b4\\ub5a8\\uae4c\\uc694? \\uc608\\ub97c \\ub4e4\\uc5b4, \\uc9c1\\uc811 \\ub9cc\\ub4e0 \\uc218\\uc81c \\ubc84\\uac70\\ub97c \\ucd94\\ucc9c\\ub4dc\\ub9bd\\ub2c8\\ub2e4.\",\n          \"\\uc608\\uc05c \\ub2e4\\uc774\\uc5b4\\ub9ac\\ub97c \\ubc1c\\uacac\\ud558\\uc168\\uad70\\uc694. \\uc800\\ub294 \\ub2e4\\uc774\\uc5b4\\ub9ac\\ub97c \\uc4f8 \\ub54c \\uae54\\ub054\\ud55c \\ub514\\uc790\\uc778\\uacfc \\ud3b8\\ub9ac\\ud55c \\ub808\\uc774\\uc544\\uc6c3\\uc744 \\uc120\\ud638\\ud574\\uc694. \\uadf8\\ub9ac\\uace0 \\ub0b4\\uad6c\\uc131 \\uc88b\\uc740 \\uc18c\\uc7ac\\ub85c \\ub9cc\\ub4e0 \\ub2e4\\uc774\\uc5b4\\ub9ac\\uac00 \\uc88b\\uc544\\uc694.\",\n          \"\\uac00\\uce20\\ub3d9\\uc740 \\ubd80\\ub4dc\\ub7ec\\uc6b4 \\ub3c8\\uae4c\\uc2a4\\uc640 \\ub2ec\\ucf64\\ud55c \\uc18c\\uc2a4\\uac00 \\uc798 \\uc5b4\\uc6b8\\ub9ac\\uc8e0! \\uc5b4\\ub514\\uc11c \\ub4dc\\uc168\\ub098\\uc694?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uad6c\\ubd84\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"\\ub300\\ud654\",\n          \"\\ub808\\uc2dc\\ud53c\\uc81c\\uacf5\",\n          \"\\uc0c1\\ud669 \\ucd94\\ucc9c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 문장을 토큰화하고 가장 긴 시퀀스 길이를 찾는 함수\n",
        "def find_max_len(dataset, tokenizer):\n",
        "    max_len = 0\n",
        "    for idx, row in dataset.iterrows():\n",
        "        q = row['Q']\n",
        "        a = row['A']\n",
        "\n",
        "        # 질문과 답변을 토큰화\n",
        "        q_toked = tokenizer.tokenize(q)\n",
        "        a_toked = tokenizer.tokenize(a)\n",
        "\n",
        "        # 토큰화된 질문과 답변의 길이 합산\n",
        "        total_len = len(q_toked) + len(a_toked)\n",
        "\n",
        "        # 최대 길이 갱신\n",
        "        if total_len > max_len:\n",
        "            max_len = total_len\n",
        "\n",
        "    return max_len\n",
        "\n",
        "# 데이터셋의 최대 토큰 길이 찾기\n",
        "max_len = find_max_len(data_set, tokenizer)\n",
        "print(f\"Max token length in the dataset: {max_len}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ArX4g4HV00U",
        "outputId": "6e034c63-c99d-447e-96b4-1c760acb6773"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max token length in the dataset: 121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 정의\n",
        "class ChatbotDataset(Dataset):\n",
        "  def __init__(self, chats, max_len=40):\n",
        "    self._data = chats\n",
        "    self.max_len = max_len\n",
        "    self.q_token = Q_TKN\n",
        "    self.a_token = A_TKN\n",
        "    self.sent_token = SENT\n",
        "    self.eos = EOS\n",
        "    self.mask = MASK\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "  def __len__(self):  # ChatbotDataset의 길이를 리턴.\n",
        "    return len(self._data)\n",
        "\n",
        "  def __getitem__(self, idx): # 로드한 ChatbotDataset을 차례차례 DataLoader로 넘겨주는 메서드\n",
        "    turn = self._data.iloc[idx]\n",
        "    q = turn[\"Q\"]  # 질문을 가져온다.\n",
        "    q = re.sub(r\"([?.!,])\", r\" \", q)  # 구둣점들을 제거한다.\n",
        "\n",
        "    a = turn[\"A\"]  # 답변을 가져온다.\n",
        "    a = re.sub(r\"([?.!,])\", r\" \", a)\n",
        "\n",
        "    q_toked = self.tokenizer.tokenize(self.q_token + q + self.sent_token)\n",
        "    q_len = len(q_toked)\n",
        "\n",
        "    a_toked = self.tokenizer.tokenize(self.a_token + a + self.eos)\n",
        "    a_len = len(a_toked)\n",
        "\n",
        "    # 질문의 길이가 최대길이보다 크면\n",
        "    if q_len > self.max_len:\n",
        "      # a_len = self.max_len - q_len  # 답변의 길이를 최대길이 - 질문길이\n",
        "      # if a_len <= 0:  # 질문의 길이가 너무 길어 질문만으로 최대 길이를 초과하면\n",
        "      #   q_toked = q_toked[-(int(self.max_len / 2)) :] # 질문길이를 최대길이의 반으로\n",
        "      #   q_len = len(q_toked)\n",
        "      #   a_len = self.max_len - q_len  # 답변의 길이를 최대길이 - 질문길이\n",
        "      # a_toked = a_toked[:a_len]\n",
        "      # a_len = len(a_toked)\n",
        "      q_toked = q_toked[-(self.max_len // 2) :] # 질문길이를 최대길이의 반으로\n",
        "      q_len = len(q_toked)\n",
        "\n",
        "    # 질문의 길이 + 답변의 길이가 최대길이보다 크면\n",
        "    if q_len + a_len > self.max_len:\n",
        "      a_len = self.max_len - q_len  # 답변의 길이를 최대길이 - 질문길이\n",
        "      # if a_len <= 0:  # 질문의 길이가 너무 길어 질문만으로 최대 길이를 초과한다면\n",
        "      #   q_toked = q_toked[-(int(self.max_len / 2)) :] # 질문길이를 최대길이의 반으로\n",
        "      #   q_len = len(q_toked)\n",
        "      #   a_len = self.max_len - q_len  # 답변의 길이를 최대길이 - 질문길이\n",
        "      a_toked = a_toked[:a_len]\n",
        "      a_len = len(a_toked)\n",
        "\n",
        "    # 답변 labels = [mask, mask, ..., mask, ..., <bos>, ...답변..., <eos>, <pad> ...]\n",
        "    labels = [self.mask,] * q_len + a_toked[1:]\n",
        "\n",
        "    # mask = 질문길이 0 + 답변길이 1 + 나머지 0\n",
        "    mask = [0] * q_len + [1] * a_len + [0] * (self.max_len - q_len - a_len)\n",
        "    # 답변 labels를 index로 만든다.\n",
        "    labels_ids = self.tokenizer.convert_tokens_to_ids(labels)\n",
        "    # 최대길이만큼 PADDING\n",
        "    while len(labels_ids) < self.max_len:\n",
        "      labels_ids += [self.tokenizer.pad_token_id]\n",
        "\n",
        "    #질문 + 답변을 index로 만든다.\n",
        "    token_ids = self.tokenizer.convert_tokens_to_ids(q_toked + a_toked)\n",
        "    # 최대길이만큼 PADDING\n",
        "    while len(token_ids) < self.max_len:\n",
        "      token_ids += [self.tokenizer.pad_token_id]\n",
        "\n",
        "    # 질문 + 답변, 마스크, 답변\n",
        "    return (token_ids, np.array(mask), labels_ids)"
      ],
      "metadata": {
        "id": "dTmaJURdMMcs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch(batch):\n",
        "  data = [item[0] for item in batch]\n",
        "  mask = [item[1] for item in batch]\n",
        "  label = [item[2] for item in batch]\n",
        "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)"
      ],
      "metadata": {
        "id": "QFw3NlY5WB0C"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = ChatbotDataset(data_set, max_len=max_len)\n",
        "train_dataloader = DataLoader(\n",
        "    train_set,\n",
        "    batch_size = 16,\n",
        "    num_workers=2,  # 윈도우->0 / 리눅스->2\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_batch,\n",
        ")\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJp4713TZA79",
        "outputId": "0f8a6405-f0b1-4dcd-90c3-b5d19256809a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(51200, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=51200, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  dataloader = tqdm(train_dataloader, desc=f\"Epoch {epoch}\")\n",
        "  # train_dataloader에서 배치 단위로 샘플을 가져와 학습.\n",
        "  for batch_idx, samples in enumerate(dataloader):\n",
        "    # Gradient 0 으로 초기화\n",
        "    optimizer.zero_grad()\n",
        "    token_ids, mask, label = samples\n",
        "\n",
        "    # 데이터 타입 확인 및 GPU로 이동\n",
        "    token_ids, mask, label = token_ids.to(device), mask.to(device), label.to(device)\n",
        "\n",
        "    out = model(token_ids)\n",
        "    out = out.logits\n",
        "    # 마스크 3D로 확장 및 출력 필터링\n",
        "    mask_3d = mask.unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2], dim=2)\n",
        "    mask_out = torch.where(mask_3d == 1, out, Sneg*torch.ones_like(out))\n",
        "\n",
        "    # 라벨 값이 클래스 개수 범위 내에 있는지 확인\n",
        "    assert label.max().item() < model.config.vocab_size, \"라벨 값이 클래스 개수보다 큽니다.\"\n",
        "\n",
        "    loss = criterion(mask_out.transpose(2, 1), label)\n",
        "    avg_loss = loss.sum() / mask.sum()\n",
        "    avg_loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99NDp48QZV2w",
        "outputId": "ad0f75b0-2da7-4000-f6e4-248f931de15e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 0:   0%|          | 0/240 [00:00<?, ?it/s]<ipython-input-9-b7a6fc7d1fcc>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n",
            "<ipython-input-9-b7a6fc7d1fcc>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "Epoch 0: 100%|██████████| 240/240 [01:30<00:00,  2.65it/s]\n",
            "Epoch 1:   0%|          | 0/240 [00:00<?, ?it/s]<ipython-input-9-b7a6fc7d1fcc>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n",
            "<ipython-input-9-b7a6fc7d1fcc>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n",
            "Epoch 1: 100%|██████████| 240/240 [01:29<00:00,  2.67it/s]\n",
            "Epoch 2:   0%|          | 0/240 [00:00<?, ?it/s]<ipython-input-9-b7a6fc7d1fcc>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n",
            "<ipython-input-9-b7a6fc7d1fcc>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n",
            "Epoch 2: 100%|██████████| 240/240 [01:29<00:00,  2.67it/s]\n",
            "Epoch 3:   0%|          | 0/240 [00:00<?, ?it/s]<ipython-input-9-b7a6fc7d1fcc>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n",
            "<ipython-input-9-b7a6fc7d1fcc>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n",
            "Epoch 3: 100%|██████████| 240/240 [01:29<00:00,  2.67it/s]\n",
            "Epoch 4:   0%|          | 0/240 [00:00<?, ?it/s]<ipython-input-9-b7a6fc7d1fcc>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n",
            "<ipython-input-9-b7a6fc7d1fcc>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n",
            "Epoch 4: 100%|██████████| 240/240 [01:29<00:00,  2.67it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "# 답변 생성 함수\n",
        "def sample_sequence(model, tokenizer, q, max_len=40, temperature=1.0, top_k=50, top_p=0.9):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        a = \"\"\n",
        "        for _ in range(max_len):\n",
        "            input_ids = torch.LongTensor(\n",
        "                tokenizer.encode(Q_TKN + q + SENT + A_TKN + a)\n",
        "            ).unsqueeze(dim=0).to(device)\n",
        "            pred = model(input_ids)\n",
        "            logits = pred.logits[:, -1, :] / temperature\n",
        "            filtered_logits = top_k_top_p_filtering(logits, top_k=top_k, top_p=top_p)\n",
        "            probabilities = torch.nn.functional.softmax(filtered_logits, dim=-1)\n",
        "            gen_id = torch.multinomial(probabilities, num_samples=1).item()\n",
        "            if gen_id >= tokenizer.vocab_size:\n",
        "                print(f\"Invalid token ID: {gen_id}\")\n",
        "                break\n",
        "            gen = tokenizer.convert_ids_to_tokens([gen_id])[0]\n",
        "            if gen == EOS:\n",
        "                break\n",
        "            a += gen.replace(\"▁\", \" \")\n",
        "        return a.strip()\n",
        "\n",
        "# logits를 필터링 하여 top-k 및 top-p 샘플링을 적용\n",
        "# top_k : 확률이 높은 상위 k개의 토큰 중에서 샘플링.\n",
        "# top_p : 누적 확률이 p 이하가 되는 상위 토큰들 중에서 샘플링\n",
        "def top_k_top_p_filtering(logits, top_k=0, top_p=0.0, filter_value=-float('Inf')):\n",
        "    # top_k 필터링\n",
        "    if top_k > 0:\n",
        "        top_k = min(top_k, logits.size(-1))\n",
        "        indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n",
        "        logits[indices_to_remove] = filter_value\n",
        "    # top_p 필터링\n",
        "    if top_p > 0.0:\n",
        "        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
        "        cumulative_probs = torch.cumsum(torch.nn.functional.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "        sorted_indices_to_remove = cumulative_probs > top_p\n",
        "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
        "        sorted_indices_to_remove[..., 0] = 0\n",
        "        indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
        "        if indices_to_remove.shape != logits.shape:\n",
        "                # print(f\"indices_to_remove shape mismatch: {indices_to_remove.shape} vs {logits.shape}\")\n",
        "                return logits\n",
        "        logits[indices_to_remove] = filter_value\n",
        "    return logits\n",
        "\n",
        "# 테스트\n",
        "with torch.no_grad():\n",
        "    while True:\n",
        "        q = input(\"user > \").strip()\n",
        "        if q == \"quit\":\n",
        "            break\n",
        "        response = sample_sequence(model, tokenizer, q, max_len=max_len, temperature=0.5, top_k=20, top_p=0.9) # temperature : 샘플링 온도로, 낮은 값은 덜 무작위 적이고, 높은 값은 더 무작위적인 결과를 만듬.\n",
        "        print(f\"Chatbot > {response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssrY4poMpX9J",
        "outputId": "2a8ce452-637e-44a6-d353-d0777009675f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user > 안녕하세요\n",
            "Chatbot > 안녕하세요  어떻게 도와드릴까요\n",
            "user > 시험을 못봤어\n",
            "Chatbot > 시험을 못봤다니 정말 속상하셨겠어요  그게 무슨 문제인가 싶을 때는 잠시 쉬어가며 공부해보는 것도 좋을 것 같아요\n",
            "user > 학교에 지각했어\n",
            "Chatbot > 학교에 지각하셨군요  지각하셨다니 정말 기쁘시겠어요  다음번엔 친구들과 함께 공부해보는 것도 좋을 것 같아요\n",
            "user > 배가 고파요\n",
            "Chatbot > 배가 고파서 많이 드신 음식이 더 맛있을 것 같아요  드셔서 기뻐요\n",
            "user > 회사에서 승진했어\n",
            "Chatbot > 회사 승진이 축하드려요  그동안의 노력과 성과가 인정받은 결과네요  앞으로도 계속해서 더 큰 성취 이루시길 바라요\n",
            "user > 오늘 여행 가기로 했어\n",
            "Chatbot > 오늘 여행 가기로 했었다니  어디로 갈 계획이세요  어디로 가면 좋을까요\n",
            "user > 요즘 날씨 너무 추워\n",
            "Chatbot > 요즘 날씨 정말 추우시겠어요  그런 날에는 따뜻한 집에서 간단한 요리를 해보는 건 어떨까요  간단한 쿠키나 머핀을 만들어보는 것도 좋은 방법이에요\n",
            "user > 오늘 본 시험이 생각보다 어려웠어\n",
            "Chatbot > 정말 아쉽겠어요  하지만 시험은 항상 어려운 일이죠  하지만 열심히 공부하셔서 좋은 결과를 얻으셨다니 다행이에요  다음번엔 더 잘할 수 있을 거예요  힘내세요  더 잘할 수 있을 거예요  함께 공부해봐요\n",
            "user > 오늘 더워서 아이스크림 먹었어\n",
            "Chatbot > 더워서 아이스크림은 정말 상큼하고 맛있죠  혹시 어떤 맛의 아이스크림을 드셨어요\n",
            "user > 초콜릿 맛 먹었어\n",
            "Chatbot > 초콜릿 맛의 드신탕은 어디서 사셨어요  어떤 종류로 드셨나요\n",
            "user > 롯데리아 햄버거가 너무 별로였어\n",
            "Chatbot > 롯데리아 햄버거가 별로였군요 햄버거는 언제나 옳죠  어떤 메뉴를 드셨어요\n",
            "user > 오늘 쉬는날인데 무엇을 하면 좋을까요?\n",
            "Chatbot > 쉬는 날에는 따뜻한 차 한 잔을 마시며 쉬어보세요  차 한 잔이 쉬는 데 큰 도움이 될 거예요\n",
            "user > 새로운 운동을 시작할거야\n",
            "Chatbot > 새로운 운동을 시작할 계획이 있으시군요  어떤 운동을 시작할 계획인가요  어떤 운동을 시작하셨나요  저도 한번 해보고 싶어요\n",
            "user > 턱걸이 할꺼야\n",
            "Chatbot > 턱걸이가 정말 편리하시다니  많이 좋아하시는 것 같아요  저도 한번 시도해보고 싶어요\n",
            "user > 취미를 추천해줘\n",
            "Chatbot > 취미를 추천해주시면 저도 좋아하는 요리를 발견했어요  저는 요리를 하면서 간단하게 즐길 수 있는 스무디를 추천드려요\n",
            "user > 새로운 취미를 찾고있어\n",
            "Chatbot > 새로운 취미를 찾고 계시군요  취미를 찾는 것은 어려운 과정일 수 있어요  하지만 꾸준히 노력하면 좋은 결과를 얻을 수 있을 거예요  응원할게요\n",
            "user > 요즘 새로운 취미를 찾고있어\n",
            "Chatbot > 새로운 취미를 찾고 계시군요  사진 찍기나 요가 같은 활동은 어떠세요  즐겁고 유익한 시간을 보낼 수 있을 거예요\n",
            "user > 오늘 마라탕먹었어\n",
            "Chatbot > 마라탕은 어떤 종류로 드셨어요  어떤 해산물이 들어간 건 정말 좋은 경험이죠  어떤 해산물이 들어갔나요\n",
            "user > 어떤 영화가 재밌어>\n",
            "Chatbot > 저는 재즈 영화 [Dynamite]의 팬텀 역을 맞았어요  재즈 음악은 정말 매력적인 음악이죠\n",
            "user > 어떤 영화가 재밌어?\n",
            "Chatbot > 재밌는 영화는 언제나 재미있죠  어떤 영화였나요  저도 한번 보고 싶네요\n",
            "user > 요즘 어떤 영화가 재밌어?\n",
            "Chatbot > 요즘 어떤 영화가 재미있으시나요  어떤 영화가 재미있나요  저도 한번 보고 싶네요\n",
            "user > 새로 나온 카페 가봤어?\n",
            "Chatbot > 새로 나온 카페 가봤어요  분위기도 좋고 커피도 맛있더라구요  조만간 같이 가볼래요\n",
            "user > 새로 생긴 식당 가봤어?\n",
            "Chatbot > 새로 생긴 식당의 가봤어요  분위기도 좋고 음식도 맛있더라구요  혹시 어떤 메뉴를 주문하셨나요\n",
            "user > 어제 오코노미야키먹었는데 맛있었어\n",
            "Chatbot > 오코노미야키는 일본식 부침개로 정말 맛있죠  어떤 부분이 가장 좋았나요\n",
            "user > 식감이 최고였어 식당 분위기도 괜찮았고\n",
            "Chatbot > 식감이 좋은 식당이 있었다니 다행이에요  좋은 시간 보내셨다니 다행이에요\n",
            "user > 오늘 집에가서 뭐하지\n",
            "Chatbot > 집에 가서 뭐하지 않더라도 간단히 집에서 간단한 스무디를 만들어보는 것은 어떨까요  어떤 스무디를 드셨어요\n",
            "user > quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "# 테스트\n",
        "with torch.no_grad():\n",
        "  while True:\n",
        "    q = input(\"user > \").strip()\n",
        "    if q == \"quit\":\n",
        "      break\n",
        "    a = \"\"\n",
        "    while 1:\n",
        "      input_ids = torch.LongTensor(\n",
        "          tokenizer.encode(Q_TKN + q + SENT + A_TKN + a)\n",
        "      ).unsqueeze(dim=0).to(device)\n",
        "      pred = model(input_ids)\n",
        "      pred = pred.logits\n",
        "      gen_id = torch.argmax(pred, dim=-1).squeeze().cpu().numpy().tolist()[-1]\n",
        "      gen = tokenizer.convert_ids_to_tokens([gen_id])[0]\n",
        "      if gen == EOS:\n",
        "        break\n",
        "      a += gen.replace(\"▁\", \" \")\n",
        "    print(f\"Chatbot > {a.strip()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzbOPhE2en-i",
        "outputId": "e58d8780-f3a7-4888-89e7-05d3f0a06480"
      },
      "execution_count": 13,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user > 안녕하세요\n",
            "Chatbot > 안녕하세요  어떻게 도와드릴까요\n",
            "user > 시험을 못봤어\n",
            "Chatbot > 시험을 못봤다니 정말 속상하시겠어요  다음번엔 다양한 범위를 공부해보는 것도 도움이 될 거예요  힘내세요  더 잘할 수 있을 거예요\n",
            "user > 학교에 지각했어\n",
            "Chatbot > 학교에 지각하셨군요  지각하셨다니 정말 기쁘시겠어요  다음 번에는 더 좋은 일 많이 하실 수 있을 거예요  기대 많이 되시겠어요\n",
            "user > 배가 고파요\n",
            "Chatbot > 배가 고파서 배가 아플 때는 신선한 재료로 배를 드셔보세요\n",
            "user > 회사에서 승진했어\n",
            "Chatbot > 정말 축하드려요  그동안의 노력과 성과가 인정받은 결과네요  앞으로도 계속해서 더 큰 성취 이루시길 바라요\n",
            "user > 오늘 여행 가기로 했어\n",
            "Chatbot > 오늘 여행 가기로 했다니  멋진 계획이에요  가족과 함께하는 여행은 소중한 추억이 될 거예요  안전하고 즐거운 여행 되시길 바랍니다\n",
            "user > 요즘 날씨 너무 추워\n",
            "Chatbot > 요즘 날씨 정말 추우시겠어요  그런 날에는 따뜻한 집에서 휴식을 취하거나 산책을 해보는 것도 좋겠어요\n",
            "user > 오늘 본 시험이 생각보다 어려웠어\n",
            "Chatbot > 정말 아쉽겠어요  하지만 시험 결과가 어찌되었든 앞으로도 계속해서 힘드실 거예요  힘내세요  더 잘할 수 있을 거예요\n",
            "user > 오늘 더워서 아이스크림 먹었어\n",
            "Chatbot > 더운 날씨에는 아이스크림이 정말 최고죠  어떤 맛을 드셨나요\n",
            "user > 초콜릿 맛 먹었어\n",
            "Chatbot > 초콜릿 맛의 드신탕은 정말 맛있죠  혹시 어떤 맛이 드셨나요\n",
            "user > 롯데리아 햄버거가 너무 별로였어\n",
            "Chatbot > 롯데리아 햄버거가 별로였군요 햄버거는 언제나 맛있었지만 햄버거는 언제나 옳았죠\n",
            "user > 오늘 쉬는날인데 무엇을 하면 좋을까요?\n",
            "Chatbot > 쉬는날에는 따뜻한 차를 마시며 쉬어보세요  예를 들어  어떤 차를 드셨어요\n",
            "user > quit\n"
          ]
        }
      ]
    }
  ]
}