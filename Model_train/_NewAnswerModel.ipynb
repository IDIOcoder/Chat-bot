{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07df406f779c48df90d1226b4239aaae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3afec54c241f4fb4b4a92cbc11b598b4",
              "IPY_MODEL_98969cf4cc624d6e9fcabc4438df233d",
              "IPY_MODEL_0a5590b2911341f3a34629bbe7126ff1"
            ],
            "layout": "IPY_MODEL_06db88fe3dba4f29818e0f000ed65ebe"
          }
        },
        "3afec54c241f4fb4b4a92cbc11b598b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abf3643707a846c3a4591fef5c65421d",
            "placeholder": "​",
            "style": "IPY_MODEL_6426ec07422d46a6802940e07ff20c1e",
            "value": "tokenizer.json: 100%"
          }
        },
        "98969cf4cc624d6e9fcabc4438df233d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1f48092c4554762819be51e27361842",
            "max": 2825034,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b31304fcb554755baedc5e9562ba385",
            "value": 2825034
          }
        },
        "0a5590b2911341f3a34629bbe7126ff1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15f7948b43a547eba1ba81759ca2ac15",
            "placeholder": "​",
            "style": "IPY_MODEL_e6d4e79076fb4b119ddb85289fba35af",
            "value": " 2.83M/2.83M [00:00&lt;00:00, 8.43MB/s]"
          }
        },
        "06db88fe3dba4f29818e0f000ed65ebe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abf3643707a846c3a4591fef5c65421d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6426ec07422d46a6802940e07ff20c1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1f48092c4554762819be51e27361842": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b31304fcb554755baedc5e9562ba385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "15f7948b43a547eba1ba81759ca2ac15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6d4e79076fb4b119ddb85289fba35af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f082ad3d4ea5448c882023dfe3d77678": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2f6bee24ada4558888c57d81bc96a10",
              "IPY_MODEL_cd4ffd175d154a72848b76149fa7cf4c",
              "IPY_MODEL_9312b7730a754061b556629a31f6f2ec"
            ],
            "layout": "IPY_MODEL_ab7fb0fbe1a84b5886b7f839268d791a"
          }
        },
        "e2f6bee24ada4558888c57d81bc96a10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_318c92aa45f547b5b137fcc9a6a65195",
            "placeholder": "​",
            "style": "IPY_MODEL_d25ad91bc57f4544a80c0e3916112357",
            "value": "config.json: 100%"
          }
        },
        "cd4ffd175d154a72848b76149fa7cf4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc61864e575246bf8f58c4908ff1ae47",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be5b91c251ea4ecda70b2e37d01ba2e9",
            "value": 1000
          }
        },
        "9312b7730a754061b556629a31f6f2ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71add6d8e7ec48ca85386b83bfd74f43",
            "placeholder": "​",
            "style": "IPY_MODEL_44fa196ac9594abd95b14b9ee5917bd8",
            "value": " 1.00k/1.00k [00:00&lt;00:00, 78.6kB/s]"
          }
        },
        "ab7fb0fbe1a84b5886b7f839268d791a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "318c92aa45f547b5b137fcc9a6a65195": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d25ad91bc57f4544a80c0e3916112357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc61864e575246bf8f58c4908ff1ae47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be5b91c251ea4ecda70b2e37d01ba2e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71add6d8e7ec48ca85386b83bfd74f43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44fa196ac9594abd95b14b9ee5917bd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30eb38b26c8745a99dc9dd11da0da7e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27a1260a97ee44a0b8278107d371db68",
              "IPY_MODEL_fc264755b56e49a0ad14623a17a53d3d",
              "IPY_MODEL_3f306e1ba7f341dcb214391c67c757e7"
            ],
            "layout": "IPY_MODEL_cc91453ec22842debbc0124a63792fd0"
          }
        },
        "27a1260a97ee44a0b8278107d371db68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db23520f3e184b3daefd2dfbeb72e58c",
            "placeholder": "​",
            "style": "IPY_MODEL_de1c9e733f784a7a81b8c129bf53d67c",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "fc264755b56e49a0ad14623a17a53d3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93503b3d80154a17ae7410b667d68ac1",
            "max": 513302779,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_142c44f5948646879956fbe6595901ea",
            "value": 513302779
          }
        },
        "3f306e1ba7f341dcb214391c67c757e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27fb94cab489418291af2008c7ca9aa8",
            "placeholder": "​",
            "style": "IPY_MODEL_c545ca58834d4f48aae1ff3c1dd998a4",
            "value": " 513M/513M [00:03&lt;00:00, 177MB/s]"
          }
        },
        "cc91453ec22842debbc0124a63792fd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db23520f3e184b3daefd2dfbeb72e58c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de1c9e733f784a7a81b8c129bf53d67c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93503b3d80154a17ae7410b667d68ac1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "142c44f5948646879956fbe6595901ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "27fb94cab489418291af2008c7ca9aa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c545ca58834d4f48aae1ff3c1dd998a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 직접 작성 (GPT2LMHeadModel)"
      ],
      "metadata": {
        "id": "RKM97yfJ2ews"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_lightning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtIMytbNbw-l",
        "outputId": "94cf8a48-55cf-4e6a-cef9-bc4d885fff70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-2.2.5-py3-none-any.whl (802 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.3/802.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2.3.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.66.4)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch_lightning)\n",
            "  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (24.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.11.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from pytorch_lightning)\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch_lightning) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->pytorch_lightning)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->pytorch_lightning) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->pytorch_lightning) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch_lightning\n",
            "Successfully installed lightning-utilities-0.11.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pytorch_lightning-2.2.5 torchmetrics-1.4.0.post0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 불러오기\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.core import LightningModule\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n",
        "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n",
        "import re, os\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "tIMe8fSB2maC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "os.environ[\"TORCH_USE_CUDA_DSA\"] = '1'"
      ],
      "metadata": {
        "id": "jxraN86XqMfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼 파라메터 설정\n",
        "Q_TKN = \"<usr>\"\n",
        "A_TKN = \"<sys>\"\n",
        "BOS = \"</s>\"\n",
        "EOS = \"</s>\"\n",
        "MASK = \"<unused0>\"\n",
        "SENT = \"<unused1>\"\n",
        "PAD = \"<pad>\"\n",
        "EPOCHS = 5\n",
        "Sneg = -1e18\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "learning_rate=3e-5"
      ],
      "metadata": {
        "id": "OGtbi6fA2_15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 토크나이저 불러오기\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
        "                                                    bos_token=BOS,\n",
        "                                                    eos_token=EOS,\n",
        "                                                    unk_token='<unk>',\n",
        "                                                    pad_token=PAD,\n",
        "                                                    mask_token=MASK)\n",
        "\n",
        "# 모델 불러오기\n",
        "model = GPT2LMHeadModel.from_pretrained(\"skt/kogpt2-base-v2\")\n",
        "\n",
        "# 데이터셋 가져오기\n",
        "data_url = \"https://raw.githubusercontent.com/IDIOcoder/Chat-bot/main/dataset/answer_dataset.csv\"\n",
        "data_set = pd.read_csv(data_url, encoding='utf-8')\n",
        "data_set.dropna(subset=[\"Q\"], inplace=True)\n",
        "data_set.dropna(subset=[\"A\"], inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324,
          "referenced_widgets": [
            "07df406f779c48df90d1226b4239aaae",
            "3afec54c241f4fb4b4a92cbc11b598b4",
            "98969cf4cc624d6e9fcabc4438df233d",
            "0a5590b2911341f3a34629bbe7126ff1",
            "06db88fe3dba4f29818e0f000ed65ebe",
            "abf3643707a846c3a4591fef5c65421d",
            "6426ec07422d46a6802940e07ff20c1e",
            "f1f48092c4554762819be51e27361842",
            "6b31304fcb554755baedc5e9562ba385",
            "15f7948b43a547eba1ba81759ca2ac15",
            "e6d4e79076fb4b119ddb85289fba35af",
            "f082ad3d4ea5448c882023dfe3d77678",
            "e2f6bee24ada4558888c57d81bc96a10",
            "cd4ffd175d154a72848b76149fa7cf4c",
            "9312b7730a754061b556629a31f6f2ec",
            "ab7fb0fbe1a84b5886b7f839268d791a",
            "318c92aa45f547b5b137fcc9a6a65195",
            "d25ad91bc57f4544a80c0e3916112357",
            "bc61864e575246bf8f58c4908ff1ae47",
            "be5b91c251ea4ecda70b2e37d01ba2e9",
            "71add6d8e7ec48ca85386b83bfd74f43",
            "44fa196ac9594abd95b14b9ee5917bd8",
            "30eb38b26c8745a99dc9dd11da0da7e3",
            "27a1260a97ee44a0b8278107d371db68",
            "fc264755b56e49a0ad14623a17a53d3d",
            "3f306e1ba7f341dcb214391c67c757e7",
            "cc91453ec22842debbc0124a63792fd0",
            "db23520f3e184b3daefd2dfbeb72e58c",
            "de1c9e733f784a7a81b8c129bf53d67c",
            "93503b3d80154a17ae7410b667d68ac1",
            "142c44f5948646879956fbe6595901ea",
            "27fb94cab489418291af2008c7ca9aa8",
            "c545ca58834d4f48aae1ff3c1dd998a4"
          ]
        },
        "id": "mLqC54Zy4cRo",
        "outputId": "32ecf4c0-da4c-44d3-a734-e48942b888ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.83M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07df406f779c48df90d1226b4239aaae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f082ad3d4ea5448c882023dfe3d77678"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/513M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30eb38b26c8745a99dc9dd11da0da7e3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_set.head(-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "k20lqTNzojBd",
        "outputId": "944d2ba2-165d-4072-9e03-a597890140c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                      Q  \\\n",
              "0     이번 프로젝트에서 발표를 하는데 내가 실수하는 바람에 우리 팀이 감점을 받았어. 너...   \n",
              "1                 회사에서 중요한 프로젝트를 혼자 하게 됐는데 솔직히 두렵고 무서워.   \n",
              "2             이번에 힘들게 들어간 첫 직장이거든. 첫 직장이라서 그런지 너무 긴장된다.   \n",
              "3                           대회에 나갔는데 예전의 내 기록을 훨씬 갱신했어!   \n",
              "4                  150만 원짜리 노트북을 샀는데 오늘 배송돼서 기분이 너무 좋아!   \n",
              "...                                                 ...   \n",
              "3830  어떡해! 내일 시험인데 공부를 전혀 안 했어. 어젯밤에 그냥 잠들어버렸어. 시험지 ...   \n",
              "3831  완전 난리 났어! 이번 시험 공부를 하나도 안 했어. 친구들은 다 공부했을 텐데, ...   \n",
              "3832  이번 시험 정말 큰일 났어! 공부를 하려고 했는데, 결국은 그냥 놀기만 했어. 시험...   \n",
              "3833  헉! 내일 시험인데 공부를 하나도 못 했어. 어제 밤에 잠들어버려서 오늘 하루 종일...   \n",
              "3834  어쩌면 좋아! 시험 준비를 전혀 안 했어. 다른 친구들은 다 열심히 공부했을 텐데,...   \n",
              "\n",
              "                                                      A  구분  \n",
              "0     그런 일이 있었군요. 실수는 누구에게나 일어날 수 있는 일이에요. 중요한 건 그것을...  대화  \n",
              "1     프로젝트를 혼자 맡는 것은 정말 큰 도전일 테지만, 동시에 많은 성장의 기회가 될 ...  대화  \n",
              "2     첫 직장은 항상 긴장되고 설레는 시간이죠. 새로운 환경에서 적응하는 것은 어려운 일...  대화  \n",
              "3     대단하시네요! 축하드립니다! 실력을 계속 향상시키고 성취를 이루는 건 정말 멋진 일...  대화  \n",
              "4     축하해요! 새로운 노트북으로 더 많은 일들을 해나가실 거예요. 새로운 도구로 무엇을...  대화  \n",
              "...                                                 ...  ..  \n",
              "3830  걱정이 많으시겠어요. 지금이라도 조금이라도 공부해보세요. 시험 전에는 긴장하지 않고...  대화  \n",
              "3831  불안해하시는 마음 이해해요. 지금이라도 조금이라도 공부해보세요. 시험 전에는 긴장하...  대화  \n",
              "3832  놀기만 해서 걱정이시겠어요. 지금이라도 조금이라도 공부해보세요. 시험 전에는 긴장하...  대화  \n",
              "3833  걱정이 많으시겠어요. 지금이라도 조금이라도 공부해보세요. 시험 전에는 긴장하지 않고...  대화  \n",
              "3834  걱정이 많으시겠어요. 지금이라도 조금이라도 공부해보세요. 시험 전에는 긴장하지 않고...  대화  \n",
              "\n",
              "[3835 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6aa1b4d-8324-4d13-99e7-dc2f04fcdd89\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>구분</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>이번 프로젝트에서 발표를 하는데 내가 실수하는 바람에 우리 팀이 감점을 받았어. 너...</td>\n",
              "      <td>그런 일이 있었군요. 실수는 누구에게나 일어날 수 있는 일이에요. 중요한 건 그것을...</td>\n",
              "      <td>대화</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>회사에서 중요한 프로젝트를 혼자 하게 됐는데 솔직히 두렵고 무서워.</td>\n",
              "      <td>프로젝트를 혼자 맡는 것은 정말 큰 도전일 테지만, 동시에 많은 성장의 기회가 될 ...</td>\n",
              "      <td>대화</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>이번에 힘들게 들어간 첫 직장이거든. 첫 직장이라서 그런지 너무 긴장된다.</td>\n",
              "      <td>첫 직장은 항상 긴장되고 설레는 시간이죠. 새로운 환경에서 적응하는 것은 어려운 일...</td>\n",
              "      <td>대화</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>대회에 나갔는데 예전의 내 기록을 훨씬 갱신했어!</td>\n",
              "      <td>대단하시네요! 축하드립니다! 실력을 계속 향상시키고 성취를 이루는 건 정말 멋진 일...</td>\n",
              "      <td>대화</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>150만 원짜리 노트북을 샀는데 오늘 배송돼서 기분이 너무 좋아!</td>\n",
              "      <td>축하해요! 새로운 노트북으로 더 많은 일들을 해나가실 거예요. 새로운 도구로 무엇을...</td>\n",
              "      <td>대화</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3830</th>\n",
              "      <td>어떡해! 내일 시험인데 공부를 전혀 안 했어. 어젯밤에 그냥 잠들어버렸어. 시험지 ...</td>\n",
              "      <td>걱정이 많으시겠어요. 지금이라도 조금이라도 공부해보세요. 시험 전에는 긴장하지 않고...</td>\n",
              "      <td>대화</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3831</th>\n",
              "      <td>완전 난리 났어! 이번 시험 공부를 하나도 안 했어. 친구들은 다 공부했을 텐데, ...</td>\n",
              "      <td>불안해하시는 마음 이해해요. 지금이라도 조금이라도 공부해보세요. 시험 전에는 긴장하...</td>\n",
              "      <td>대화</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3832</th>\n",
              "      <td>이번 시험 정말 큰일 났어! 공부를 하려고 했는데, 결국은 그냥 놀기만 했어. 시험...</td>\n",
              "      <td>놀기만 해서 걱정이시겠어요. 지금이라도 조금이라도 공부해보세요. 시험 전에는 긴장하...</td>\n",
              "      <td>대화</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3833</th>\n",
              "      <td>헉! 내일 시험인데 공부를 하나도 못 했어. 어제 밤에 잠들어버려서 오늘 하루 종일...</td>\n",
              "      <td>걱정이 많으시겠어요. 지금이라도 조금이라도 공부해보세요. 시험 전에는 긴장하지 않고...</td>\n",
              "      <td>대화</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3834</th>\n",
              "      <td>어쩌면 좋아! 시험 준비를 전혀 안 했어. 다른 친구들은 다 열심히 공부했을 텐데,...</td>\n",
              "      <td>걱정이 많으시겠어요. 지금이라도 조금이라도 공부해보세요. 시험 전에는 긴장하지 않고...</td>\n",
              "      <td>대화</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3835 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6aa1b4d-8324-4d13-99e7-dc2f04fcdd89')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a6aa1b4d-8324-4d13-99e7-dc2f04fcdd89 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a6aa1b4d-8324-4d13-99e7-dc2f04fcdd89');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6960d6a9-fa43-4cd7-8aae-b4ba7e3f038c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6960d6a9-fa43-4cd7-8aae-b4ba7e3f038c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6960d6a9-fa43-4cd7-8aae-b4ba7e3f038c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_set",
              "summary": "{\n  \"name\": \"data_set\",\n  \"rows\": 3836,\n  \"fields\": [\n    {\n      \"column\": \"Q\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3503,\n        \"samples\": [\n          \"\\uadf8 \\uc0ac\\ub78c\\uc774 \\ub098\\ub97c \\uc5b4\\ub5bb\\uac8c \\uc0dd\\uac01\\ud558\\ub294\\uc9c0 \\uc54c \\uc218 \\uc5c6\\uc5b4\\uc11c \\uad34\\ub85c\\uc6cc.\",\n          \"\\uc81c \\uc5f0\\uc778\\uacfc \\ub9ce\\uc774 \\uc2f8\\uc6cc\\uc11c \\ud798\\ub4e4\\uc5b4\\uc694.\",\n          \"\\uc5b4\\uc81c \\ubc24\\uc0c8\\uc11c \\uc791\\uc5c5\\ud588\\ub294\\ub370 \\ub4dc\\ub514\\uc5b4 \\ub05d\\ub0ac\\uc5b4! \\ub108\\ubb34 \\ubfcc\\ub4ef\\ud574.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"A\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3553,\n        \"samples\": [\n          \"\\uc5c5\\ubb34 \\uc555\\ubc15\\uc744 \\ub290\\ub07c\\uc2e0\\ub2e4\\uba74, \\uc77c\\uc744 \\uc7a0\\uc2dc \\uba48\\ucd94\\uace0 \\uc9e7\\uc740 \\uc0b0\\ucc45\\uc774\\ub098 \\uba85\\uc0c1 \\uc2dc\\uac04\\uc744 \\uac00\\uc838\\ubcf4\\uc138\\uc694. \\uadf8\\ub9ac\\uace0 \\uc5c5\\ubb34 \\ud6c4\\uc5d0\\ub294 \\uc790\\uc2e0\\uc744 \\uc704\\ud55c \\ud2b9\\ubcc4\\ud55c \\uc800\\ub141\\uc744 \\uc900\\ube44\\ud574\\ubcf4\\ub294 \\uac74 \\uc5b4\\ub5a8\\uae4c\\uc694? \\uc608\\ub97c \\ub4e4\\uc5b4, \\uc9c1\\uc811 \\ub9cc\\ub4e0 \\uc218\\uc81c \\ubc84\\uac70\\ub97c \\ucd94\\ucc9c\\ub4dc\\ub9bd\\ub2c8\\ub2e4.\",\n          \"\\uc608\\uc05c \\ub2e4\\uc774\\uc5b4\\ub9ac\\ub97c \\ubc1c\\uacac\\ud558\\uc168\\uad70\\uc694. \\uc800\\ub294 \\ub2e4\\uc774\\uc5b4\\ub9ac\\ub97c \\uc4f8 \\ub54c \\uae54\\ub054\\ud55c \\ub514\\uc790\\uc778\\uacfc \\ud3b8\\ub9ac\\ud55c \\ub808\\uc774\\uc544\\uc6c3\\uc744 \\uc120\\ud638\\ud574\\uc694. \\uadf8\\ub9ac\\uace0 \\ub0b4\\uad6c\\uc131 \\uc88b\\uc740 \\uc18c\\uc7ac\\ub85c \\ub9cc\\ub4e0 \\ub2e4\\uc774\\uc5b4\\ub9ac\\uac00 \\uc88b\\uc544\\uc694.\",\n          \"\\uac00\\uce20\\ub3d9\\uc740 \\ubd80\\ub4dc\\ub7ec\\uc6b4 \\ub3c8\\uae4c\\uc2a4\\uc640 \\ub2ec\\ucf64\\ud55c \\uc18c\\uc2a4\\uac00 \\uc798 \\uc5b4\\uc6b8\\ub9ac\\uc8e0! \\uc5b4\\ub514\\uc11c \\ub4dc\\uc168\\ub098\\uc694?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uad6c\\ubd84\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"\\ub300\\ud654\",\n          \"\\ub808\\uc2dc\\ud53c\\uc81c\\uacf5\",\n          \"\\uc0c1\\ud669 \\ucd94\\ucc9c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 문장을 토큰화하고 가장 긴 시퀀스 길이를 찾는 함수\n",
        "def find_max_len(dataset, tokenizer):\n",
        "    max_len = 0\n",
        "    for idx, row in dataset.iterrows():\n",
        "        q = row['Q']\n",
        "        a = row['A']\n",
        "\n",
        "        # 질문과 답변을 토큰화\n",
        "        q_toked = tokenizer.tokenize(q)\n",
        "        a_toked = tokenizer.tokenize(a)\n",
        "\n",
        "        # 토큰화된 질문과 답변의 길이 합산\n",
        "        total_len = len(q_toked) + len(a_toked)\n",
        "\n",
        "        # 최대 길이 갱신\n",
        "        if total_len > max_len:\n",
        "            max_len = total_len\n",
        "\n",
        "    return max_len\n",
        "\n",
        "# 데이터셋의 최대 토큰 길이 찾기\n",
        "max_len = find_max_len(data_set, tokenizer)\n",
        "print(f\"Max token length in the dataset: {max_len}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ArX4g4HV00U",
        "outputId": "bbc6eff6-edaf-445b-bb38-1ef2fd5d19a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max token length in the dataset: 121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 정의\n",
        "class ChatbotDataset(Dataset):\n",
        "  def __init__(self, chats, max_len=40):\n",
        "    self._data = chats\n",
        "    self.max_len = max_len\n",
        "    self.q_token = Q_TKN\n",
        "    self.a_token = A_TKN\n",
        "    self.sent_token = SENT\n",
        "    self.eos = EOS\n",
        "    self.mask = MASK\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "  def __len__(self):  # ChatbotDataset의 길이를 리턴.\n",
        "    return len(self._data)\n",
        "\n",
        "  def __getitem__(self, idx): # 로드한 ChatbotDataset을 차례차례 DataLoader로 넘겨주는 메서드\n",
        "    turn = self._data.iloc[idx]\n",
        "    q = turn[\"Q\"]  # 질문을 가져온다.\n",
        "\n",
        "    a = turn[\"A\"]  # 답변을 가져온다.\n",
        "\n",
        "    q_toked = self.tokenizer.tokenize(self.q_token + q + self.sent_token)\n",
        "    q_len = len(q_toked)\n",
        "\n",
        "    a_toked = self.tokenizer.tokenize(self.a_token + a + self.eos)\n",
        "    a_len = len(a_toked)\n",
        "\n",
        "    # 질문의 길이가 최대길이보다 크면\n",
        "    if q_len > self.max_len:\n",
        "      q_toked = q_toked[-(self.max_len // 2) :] # 질문길이를 최대길이의 반으로\n",
        "      q_len = len(q_toked)\n",
        "\n",
        "    # 질문의 길이 + 답변의 길이가 최대길이보다 크면\n",
        "    if q_len + a_len > self.max_len:\n",
        "      a_len = self.max_len - q_len\n",
        "      a_toked = a_toked[:a_len]\n",
        "      a_len = len(a_toked)\n",
        "\n",
        "    # 답변 labels = [mask, mask, ..., mask, ..., <bos>, ...답변..., <eos>, <pad> ...]\n",
        "    labels = [self.mask,] * q_len + a_toked[1:]\n",
        "\n",
        "    # mask = 질문길이 0 + 답변길이 1 + 나머지 0\n",
        "    mask = [0] * q_len + [1] * a_len + [0] * (self.max_len - q_len - a_len)\n",
        "    # 답변 labels를 index로 만든다.\n",
        "    labels_ids = self.tokenizer.convert_tokens_to_ids(labels)\n",
        "    labels_ids += [self.tokenizer.pad_token_id] * (self.max_len - len(labels_ids))\n",
        "\n",
        "    #질문 + 답변을 index로 만든다.\n",
        "    token_ids = self.tokenizer.convert_tokens_to_ids(q_toked + a_toked)\n",
        "    token_ids += [self.tokenizer.pad_token_id] * (self.max_len - len(token_ids))\n",
        "\n",
        "    # 질문 + 답변, 마스크, 답변\n",
        "    return (token_ids, np.array(mask), labels_ids)"
      ],
      "metadata": {
        "id": "dTmaJURdMMcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch(batch):\n",
        "  data = [item[0] for item in batch]\n",
        "  mask = [item[1] for item in batch]\n",
        "  label = [item[2] for item in batch]\n",
        "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)"
      ],
      "metadata": {
        "id": "QFw3NlY5WB0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = ChatbotDataset(data_set, max_len=max_len)\n",
        "train_dataloader = DataLoader(\n",
        "    train_set,\n",
        "    batch_size = 16,\n",
        "    num_workers=2,  # 윈도우->0 / 리눅스->2\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_batch,\n",
        ")\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJp4713TZA79",
        "outputId": "f31a26f4-d618-4559-a6ff-4f0d5827ad4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(51200, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=51200, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  dataloader = tqdm(train_dataloader, desc=f\"Epoch {epoch}\")\n",
        "  # train_dataloader에서 배치 단위로 샘플을 가져와 학습.\n",
        "  for batch_idx, samples in enumerate(dataloader):\n",
        "    # Gradient 0 으로 초기화\n",
        "    optimizer.zero_grad()\n",
        "    token_ids, mask, label = samples\n",
        "\n",
        "    # 데이터 타입 확인 및 GPU로 이동\n",
        "    token_ids, mask, label = token_ids.to(device), mask.to(device), label.to(device)\n",
        "\n",
        "    out = model(token_ids)\n",
        "    out = out.logits\n",
        "    # 마스크 3D로 확장 및 출력 필터링\n",
        "    mask_3d = mask.unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2], dim=2)\n",
        "    mask_out = torch.where(mask_3d == 1, out, Sneg*torch.ones_like(out))\n",
        "\n",
        "    # 라벨 값이 클래스 개수 범위 내에 있는지 확인\n",
        "    assert label.max().item() < model.config.vocab_size, \"라벨 값이 클래스 개수보다 큽니다.\"\n",
        "\n",
        "    loss = criterion(mask_out.transpose(2, 1), label)\n",
        "    avg_loss = loss.sum() / mask.sum()\n",
        "    avg_loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99NDp48QZV2w",
        "outputId": "35e444bf-3b1d-4bfb-bf29-0b3be0134074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 0:   0%|          | 0/240 [00:00<?, ?it/s]<ipython-input-9-b7a6fc7d1fcc>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n",
            "<ipython-input-9-b7a6fc7d1fcc>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "Epoch 0: 100%|██████████| 240/240 [01:29<00:00,  2.67it/s]\n",
            "Epoch 1:   0%|          | 0/240 [00:00<?, ?it/s]<ipython-input-9-b7a6fc7d1fcc>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n",
            "<ipython-input-9-b7a6fc7d1fcc>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n",
            "Epoch 1: 100%|██████████| 240/240 [01:29<00:00,  2.69it/s]\n",
            "Epoch 2:   0%|          | 0/240 [00:00<?, ?it/s]<ipython-input-9-b7a6fc7d1fcc>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n",
            "<ipython-input-9-b7a6fc7d1fcc>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n",
            "Epoch 2: 100%|██████████| 240/240 [01:29<00:00,  2.69it/s]\n",
            "Epoch 3:   0%|          | 0/240 [00:00<?, ?it/s]<ipython-input-9-b7a6fc7d1fcc>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n",
            "<ipython-input-9-b7a6fc7d1fcc>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n",
            "Epoch 3: 100%|██████████| 240/240 [01:29<00:00,  2.69it/s]\n",
            "Epoch 4:   0%|          | 0/240 [00:00<?, ?it/s]<ipython-input-9-b7a6fc7d1fcc>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n",
            "<ipython-input-9-b7a6fc7d1fcc>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n",
            "Epoch 4: 100%|██████████| 240/240 [01:29<00:00,  2.69it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "# 답변 생성 함수\n",
        "def sample_sequence(model, tokenizer, q, max_len=40, temperature=1.0, top_k=50, top_p=0.9):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        a = \"\"\n",
        "        for _ in range(max_len):\n",
        "            input_ids = torch.LongTensor(\n",
        "                tokenizer.encode(Q_TKN + q + SENT + A_TKN + a)\n",
        "            ).unsqueeze(dim=0).to(device)\n",
        "            pred = model(input_ids)\n",
        "            logits = pred.logits[:, -1, :] / temperature\n",
        "            filtered_logits = top_k_top_p_filtering(logits, top_k=top_k, top_p=top_p)\n",
        "            probabilities = torch.nn.functional.softmax(filtered_logits, dim=-1)\n",
        "            gen_id = torch.multinomial(probabilities, num_samples=1).item()\n",
        "            if gen_id >= tokenizer.vocab_size:\n",
        "                print(f\"Invalid token ID: {gen_id}\")\n",
        "                break\n",
        "            gen = tokenizer.convert_ids_to_tokens([gen_id])[0]\n",
        "            if gen == EOS:\n",
        "                break\n",
        "            a += gen.replace(\"▁\", \" \")\n",
        "        return a.strip()\n",
        "\n",
        "# logits를 필터링 하여 top-k 및 top-p 샘플링을 적용\n",
        "# top_k : 확률이 높은 상위 k개의 토큰 중에서 샘플링.\n",
        "# top_p : 누적 확률이 p 이하가 되는 상위 토큰들 중에서 샘플링\n",
        "def top_k_top_p_filtering(logits, top_k=0, top_p=0.0, filter_value=-float('Inf')):\n",
        "    # top_k 필터링\n",
        "    if top_k > 0:\n",
        "        top_k = min(top_k, logits.size(-1))\n",
        "        indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n",
        "        logits[indices_to_remove] = filter_value\n",
        "    # top_p 필터링\n",
        "    if top_p > 0.0:\n",
        "        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
        "        cumulative_probs = torch.cumsum(torch.nn.functional.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "        sorted_indices_to_remove = cumulative_probs > top_p\n",
        "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
        "        sorted_indices_to_remove[..., 0] = 0\n",
        "        indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
        "        if indices_to_remove.shape != logits.shape:\n",
        "                # print(f\"indices_to_remove shape mismatch: {indices_to_remove.shape} vs {logits.shape}\")\n",
        "                return logits\n",
        "        logits[indices_to_remove] = filter_value\n",
        "    return logits\n",
        "\n",
        "# 테스트\n",
        "with torch.no_grad():\n",
        "    while True:\n",
        "        q = input(\"user > \").strip()\n",
        "        if q == \"quit\":\n",
        "            break\n",
        "        response = sample_sequence(model, tokenizer, q, max_len=max_len, temperature=0.5, top_k=20, top_p=0.9) # temperature : 샘플링 온도로, 낮은 값은 덜 무작위 적이고, 높은 값은 더 무작위적인 결과를 만듬.\n",
        "        print(f\"Chatbot > {response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssrY4poMpX9J",
        "outputId": "67b4ced4-6430-4fe5-d87d-e836c5e93699"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user > 오늘 날씨가 어때?\n",
            "Chatbot > 오늘 날씨가 어때요? 날씨도 정말 좋은 것 같아요.\n",
            "user > 안녕?\n",
            "Chatbot > 안녕하세요! 오늘 하루도 좋은 하루 되세요.\n",
            "user > 너무 배가 고파\n",
            "Chatbot > 음식이 너무 맛있으면 기분이 좋으신가요?\n",
            "user > 맛이있지는 안항\n",
            "Chatbot > 그게 중요하죠. 혹시 추가적으로 더 맛있는 식사 하세요.\n",
            "user > 아니 음식이 맛없어\n",
            "Chatbot > 아니 음식이 맛없다고 느껴질 때는 그 음식을 다시 만들어 먹을 수 있는 기회를 만들어보세요. 그 기회를 잘 활용하면 더 맛있게 드실 수 있을 거예요.\n",
            "user > 오늘 기분이 어떄?\n",
            "Chatbot > 오늘 기분이 어때요? 그런 날이 가끔 있어요. 그런 날은 충분히 휴식을 취하며 좋아하는 음악을 듣는 것도 도움이 될 거예요.\n",
            "user > 오늘 기분이 너무 안좋아\n",
            "Chatbot > 기분이 안좋아질 때는 자신에게 충분한 휴식을 취하고, 자신에게 긍정적인 생각을 가져보세요.\n",
            "user > 밥이 너무 맛이없어\n",
            "Chatbot > 밥의 맛이 없으신다니 정말 아쉽겠어요. 다음에도 맛있게 드세요.\n",
            "user > 맛이 없다니까\n",
            "Chatbot > 맛 없으신다니 후회되시겠어요. 다음 번에는 다양한 재료로 맛을 더해보세요.\n",
            "user > 여행을 가고싶어\n",
            "Chatbot > 여행을 가고 싶으시군요. 여행의 즐거움과 휴식을 함께 즐기며 건강한 생활을 즐겨보세요.\n",
            "user > 여행지는 어디가 좋아?=\n",
            "Chatbot > 여행지는 제주도가 좋아요. 자연경관도 아름답고 맛집도 많아요. 추천해주세요.\n",
            "user > 여행지는 제주도가 좋아?\n",
            "Chatbot > 여행지는 여러 곳이 있어요. 자연경관도 아름답고 맛집도 많아요. 한번 가보시면 후회하지 않으실 거예요!\n",
            "user > 제주도는 어때?\n",
            "Chatbot > 네, 제주도는 정말 맛있죠! 어떤 음식을 드셨나요?\n",
            "user > 여행은 어디를 가야할까?\n",
            "Chatbot > 여행은 주로 제주도가 좋죠. 자연경관도 아름답고 맛집도 많아요.\n",
            "user > 해외여행은?\n",
            "Chatbot > 네, 해외여행은 베트남에서 하고 있어요. 현지 음식을 맛보고 음식도 맛보는 시간이 재미있을 것 같아요.\n",
            "user > 해외여행은 어디로 가야할까?\n",
            "Chatbot > 해외여행을 계획하신다면 먼저 현지 문화에 맞는 여행지를 찾아보는 것이 중요해요. 꼭 한번 가보고 싶은 곳이 있다면 언제든 찾아가는 여행사가 있어요!\n",
            "user > 오늘 친구랑 싸웠어. 어떻게 사과하는게 좋을까?\n",
            "Chatbot > 싸웠던 이유를 이야기해보세요. \"너에게 상처 줄 의도는 전혀 없었어요. 진심으로 사과 드리고 함께 시간을 보내요!\" 같은 대답이 가장 좋았다고 전해주세요.\n",
            "user > 오늘 쉬는날인데 뭘 하면서 시간을 보내는게 좋을까?\n",
            "Chatbot > 하루 쉬는날에는 좋아하는 음식을 만들어서 요리해보는 것도 좋은 시간이 될 거예요.\n",
            "user > 주말에 뭘 하는게 좋을까?\n",
            "Chatbot > 주말에 뭘 하는게 좋을지 고민되실 수 있어요. 자신에게 맞는 취미나 관심사를 찾아보는 것이 중요해요.\n",
            "user > 요리를 해보고 싶어요\n",
            "Chatbot > 요리를 해보고 싶다면 먼저 신선한 재료로 만든 요리를 추천해 주세요. 신선한 재료가 가득하면 요리가 정말 맛있죠. 맛있게 드실 수 있을 거예요!\n",
            "user > 해외여행 계획 중이에요.\n",
            "Chatbot > 해외여행 계획 중이신가요? 여행지의 다양한 음식을 맛보는 것도 큰 목표예요.\n",
            "user > 해외여행 어디로 가볼까?\n",
            "Chatbot > 해외여행을 계획하신다면, 현지 여행지의 다양한 음식을 맛보는 것도 큰 즐거움이죠. 어떤 여행지를 가보고 싶으세요?\n",
            "user > 이탈리아에 가보고 싶어\n",
            "Chatbot > 이탈리아에 가보고 싶다면 이탈리아 사람들의 생활에 큰 관심을 가지고, 작은 가게부터 들어보세요. 관심을 표현하고, 새로운 경험을 해보는 것도 좋을 것 같아요.\n",
            "user > 친구들이랑 한강 다녀왔어\n",
            "Chatbot > 친구들과 함께 한강변을 다녀오셨다니 정말 멋진 시간이었겠어요. 일상에서 자주 만나면 더 큰 즐거움을 찾을 수 있을 것 같아요.\n",
            "user > 친구들이랑 피크닉 다녀왔어\n",
            "Chatbot > 피크닉은 친구들과 함께 즐거운 시간을 보내기 좋은 시간이었겠어요.\n",
            "user > 저녁으로 뭘 먹어야 할지 고민이야.\n",
            "Chatbot > 뭘 먹어야 할지 고민이 많으시군요. 다양한 토핑을 추가해서 고민해보세요.\n",
            "user > quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "# 테스트\n",
        "with torch.no_grad():\n",
        "  while True:\n",
        "    q = input(\"user > \").strip()\n",
        "    if q == \"quit\":\n",
        "      break\n",
        "    a = \"\"\n",
        "    while 1:\n",
        "      input_ids = torch.LongTensor(\n",
        "          tokenizer.encode(Q_TKN + q + SENT + A_TKN + a)\n",
        "      ).unsqueeze(dim=0).to(device)\n",
        "      pred = model(input_ids)\n",
        "      pred = pred.logits\n",
        "      gen_id = torch.argmax(pred, dim=-1).squeeze().cpu().numpy().tolist()[-1]\n",
        "      gen = tokenizer.convert_ids_to_tokens([gen_id])[0]\n",
        "      if gen == EOS:\n",
        "        break\n",
        "      a += gen.replace(\"▁\", \" \")\n",
        "    print(f\"Chatbot > {a.strip()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzbOPhE2en-i",
        "outputId": "5e3e6d37-cb10-4b9f-f399-89decf3e66b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user > 저녁으로 뭘 먹어야 할지 고민이야.\n",
            "Chatbot > 뭘 먹어야 할지 고민이 많으시군요. 다양한 재료로 디저트를 만들어보는 것도 좋겠네요.\n",
            "user > 디저트로 저녁을 해결하고 싶지는 않아.\n",
            "Chatbot > 디저트로 저녁을 해결하고 싶다면 어떤 메뉴를 드시고 싶으세요?\n",
            "user > 친구들이랑 피크닉 다녀왔어\n",
            "Chatbot > 피크닉은 친구들과 함께 즐거운 시간을 보내기 좋은 좋은 시간이에요!\n",
            "user > 친구들이랑 한강으로 놀러 갔다왔어.\n",
            "Chatbot > 친구들과 함께 한강으로 놀러 가셨군요! 가족과 함께하는 시간은 언제나 소중하고 즐거울 거예요. 안전하고 즐거운 시간 보내시길 바랍니다.\n",
            "user > quit\n"
          ]
        }
      ]
    }
  ]
}