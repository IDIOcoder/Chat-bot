{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "275b6f6a44af4bdeac636b6d3dd621e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_993eb235057c4bebac806eda4df65bbf",
              "IPY_MODEL_548322702e63409ebb2902511f3da480",
              "IPY_MODEL_39b6ceacbd704d3696bfa06614cb5cf7"
            ],
            "layout": "IPY_MODEL_ce354c3f2dc640d0b13267062bb233fc"
          }
        },
        "993eb235057c4bebac806eda4df65bbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a3ab116cf3d49dd807e1ff06cafa9d6",
            "placeholder": "​",
            "style": "IPY_MODEL_8cdabd43989245099e839bf9b4e10776",
            "value": "tokenizer.json: 100%"
          }
        },
        "548322702e63409ebb2902511f3da480": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9e4ccdf91ac4b8f993cf0f871b0174f",
            "max": 2825034,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad9d615bb7664f428431e9b02ad830f7",
            "value": 2825034
          }
        },
        "39b6ceacbd704d3696bfa06614cb5cf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2dc847a1b1c49119ef4b138dd777720",
            "placeholder": "​",
            "style": "IPY_MODEL_0d33525e17024432a25028c5a7fcbb38",
            "value": " 2.83M/2.83M [00:00&lt;00:00, 8.30MB/s]"
          }
        },
        "ce354c3f2dc640d0b13267062bb233fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a3ab116cf3d49dd807e1ff06cafa9d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cdabd43989245099e839bf9b4e10776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9e4ccdf91ac4b8f993cf0f871b0174f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad9d615bb7664f428431e9b02ad830f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2dc847a1b1c49119ef4b138dd777720": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d33525e17024432a25028c5a7fcbb38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad188300138d45f898bab04b5bdbe87c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_beb7f222450d484b84c86c8f4938b9a7",
              "IPY_MODEL_f5e45cc2ebc34b8fa3b5c757fc284865",
              "IPY_MODEL_0cb996ea6bc1424a92aceb7c8c9374ea"
            ],
            "layout": "IPY_MODEL_e5ee1135a6a145aab38dca5b6d92fe51"
          }
        },
        "beb7f222450d484b84c86c8f4938b9a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_112fca96a88d4392bf052c01d66812b0",
            "placeholder": "​",
            "style": "IPY_MODEL_795fa0d4d63f405e914e4c6219eee79f",
            "value": "config.json: 100%"
          }
        },
        "f5e45cc2ebc34b8fa3b5c757fc284865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d4dacbf827b46d1bbbbdddd390ca9df",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1fa4c7c0e5f542cdad64e7fc0cecd90a",
            "value": 1000
          }
        },
        "0cb996ea6bc1424a92aceb7c8c9374ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d8d417ab4a24b839025ac6de782f6d8",
            "placeholder": "​",
            "style": "IPY_MODEL_85ea5027e21f4f07a5276b98ea036681",
            "value": " 1.00k/1.00k [00:00&lt;00:00, 76.1kB/s]"
          }
        },
        "e5ee1135a6a145aab38dca5b6d92fe51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "112fca96a88d4392bf052c01d66812b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "795fa0d4d63f405e914e4c6219eee79f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d4dacbf827b46d1bbbbdddd390ca9df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fa4c7c0e5f542cdad64e7fc0cecd90a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d8d417ab4a24b839025ac6de782f6d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85ea5027e21f4f07a5276b98ea036681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c20bb750602e4fb5ac9cf8755d7989c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd12e28411e44ea6942656dc443c33c9",
              "IPY_MODEL_96f9f6fbf2a04ff8bbea8ae7fedcc19b",
              "IPY_MODEL_e484c51734ce46bf973bcfe14e84efb0"
            ],
            "layout": "IPY_MODEL_bc12df01e8934ae3be21bfc02f98e1a4"
          }
        },
        "fd12e28411e44ea6942656dc443c33c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fd82306e6e9447f8fe57ec485f86c7d",
            "placeholder": "​",
            "style": "IPY_MODEL_5f8c857c097c400ea0d23af223cfd87f",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "96f9f6fbf2a04ff8bbea8ae7fedcc19b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4aac0e15bfd242a88e82783873c06abf",
            "max": 513302779,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8288ee6bad1140e7a644bff5cc34c7a5",
            "value": 513302779
          }
        },
        "e484c51734ce46bf973bcfe14e84efb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71d517ff34ef48c299988c1c6880a960",
            "placeholder": "​",
            "style": "IPY_MODEL_f141ed16d9fc43f2ba72d6a6e50171a1",
            "value": " 513M/513M [00:19&lt;00:00, 20.2MB/s]"
          }
        },
        "bc12df01e8934ae3be21bfc02f98e1a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fd82306e6e9447f8fe57ec485f86c7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f8c857c097c400ea0d23af223cfd87f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4aac0e15bfd242a88e82783873c06abf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8288ee6bad1140e7a644bff5cc34c7a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71d517ff34ef48c299988c1c6880a960": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f141ed16d9fc43f2ba72d6a6e50171a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 필요모듈 설치"
      ],
      "metadata": {
        "id": "RKM97yfJ2ews"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_lightning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtIMytbNbw-l",
        "outputId": "398f0f22-6bc7-4502-aa6c-f7b3f7f9f98a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-2.2.5-py3-none-any.whl (802 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.3/802.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2.3.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.66.4)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch_lightning)\n",
            "  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (24.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.11.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from pytorch_lightning)\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch_lightning) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13.0->pytorch_lightning)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->pytorch_lightning)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->pytorch_lightning) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->pytorch_lightning) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch_lightning\n",
            "Successfully installed lightning-utilities-0.11.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pytorch_lightning-2.2.5 torchmetrics-1.4.0.post0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 라이브러리 불러오기"
      ],
      "metadata": {
        "id": "V61TuvFreLFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 불러오기\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.core import LightningModule\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n",
        "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n",
        "import re, os\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "tIMe8fSB2maC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "os.environ[\"TORCH_USE_CUDA_DSA\"] = '1'"
      ],
      "metadata": {
        "id": "jxraN86XqMfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 하이퍼 파라메터 설정"
      ],
      "metadata": {
        "id": "7XGYnskZeQXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼 파라메터 설정\n",
        "Q_TKN = \"<usr>\"\n",
        "A_TKN = \"<sys>\"\n",
        "BOS = \"</s>\"\n",
        "EOS = \"</s>\"\n",
        "MASK = \"<unused0>\"\n",
        "SENT = \"<unused1>\"\n",
        "PAD = \"<pad>\"\n",
        "EPOCHS = 5\n",
        "Sneg = -1e18\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "learning_rate = 3e-5"
      ],
      "metadata": {
        "id": "OGtbi6fA2_15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 토크나이저 & 모델 & 데이터셋 불러오기\n"
      ],
      "metadata": {
        "id": "XOshmCeGeT6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 토크나이저 불러오기\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
        "                                                    bos_token=BOS,\n",
        "                                                    eos_token=EOS,\n",
        "                                                    unk_token='<unk>',\n",
        "                                                    pad_token=PAD,\n",
        "                                                    mask_token=MASK)\n",
        "\n",
        "# 모델 불러오기\n",
        "model = GPT2LMHeadModel.from_pretrained(\"skt/kogpt2-base-v2\")\n",
        "model.to(device)\n",
        "\n",
        "# 데이터셋 가져오기\n",
        "data_url = \"https://raw.githubusercontent.com/IDIOcoder/Chat-bot/main/dataset/answer_dataset_1.csv\"\n",
        "data_set = pd.read_csv(data_url, encoding='utf-8')\n",
        "data_set.dropna(subset=[\"Q\"], inplace=True)\n",
        "data_set.dropna(subset=[\"A\"], inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329,
          "referenced_widgets": [
            "275b6f6a44af4bdeac636b6d3dd621e3",
            "993eb235057c4bebac806eda4df65bbf",
            "548322702e63409ebb2902511f3da480",
            "39b6ceacbd704d3696bfa06614cb5cf7",
            "ce354c3f2dc640d0b13267062bb233fc",
            "1a3ab116cf3d49dd807e1ff06cafa9d6",
            "8cdabd43989245099e839bf9b4e10776",
            "b9e4ccdf91ac4b8f993cf0f871b0174f",
            "ad9d615bb7664f428431e9b02ad830f7",
            "e2dc847a1b1c49119ef4b138dd777720",
            "0d33525e17024432a25028c5a7fcbb38",
            "ad188300138d45f898bab04b5bdbe87c",
            "beb7f222450d484b84c86c8f4938b9a7",
            "f5e45cc2ebc34b8fa3b5c757fc284865",
            "0cb996ea6bc1424a92aceb7c8c9374ea",
            "e5ee1135a6a145aab38dca5b6d92fe51",
            "112fca96a88d4392bf052c01d66812b0",
            "795fa0d4d63f405e914e4c6219eee79f",
            "9d4dacbf827b46d1bbbbdddd390ca9df",
            "1fa4c7c0e5f542cdad64e7fc0cecd90a",
            "9d8d417ab4a24b839025ac6de782f6d8",
            "85ea5027e21f4f07a5276b98ea036681",
            "c20bb750602e4fb5ac9cf8755d7989c0",
            "fd12e28411e44ea6942656dc443c33c9",
            "96f9f6fbf2a04ff8bbea8ae7fedcc19b",
            "e484c51734ce46bf973bcfe14e84efb0",
            "bc12df01e8934ae3be21bfc02f98e1a4",
            "3fd82306e6e9447f8fe57ec485f86c7d",
            "5f8c857c097c400ea0d23af223cfd87f",
            "4aac0e15bfd242a88e82783873c06abf",
            "8288ee6bad1140e7a644bff5cc34c7a5",
            "71d517ff34ef48c299988c1c6880a960",
            "f141ed16d9fc43f2ba72d6a6e50171a1"
          ]
        },
        "id": "mLqC54Zy4cRo",
        "outputId": "196f3438-5c04-434c-ce57-24050f5fb08b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.83M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "275b6f6a44af4bdeac636b6d3dd621e3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad188300138d45f898bab04b5bdbe87c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/513M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c20bb750602e4fb5ac9cf8755d7989c0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_set.head(-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "k20lqTNzojBd",
        "outputId": "1302e572-7c85-41ff-e41e-c430526105fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                      Q  \\\n",
              "0     이번 프로젝트에서 발표를 하는데 내가 실수하는 바람에 우리 팀이 감점을 받았어. 너...   \n",
              "1                 회사에서 중요한 프로젝트를 혼자 하게 됐는데 솔직히 두렵고 무서워.   \n",
              "2             이번에 힘들게 들어간 첫 직장이거든. 첫 직장이라서 그런지 너무 긴장된다.   \n",
              "3                           대회에 나갔는데 예전의 내 기록을 훨씬 갱신했어!   \n",
              "4                  150만 원짜리 노트북을 샀는데 오늘 배송돼서 기분이 너무 좋아!   \n",
              "...                                                 ...   \n",
              "4009                              가장 맛있는 파스타는 어떤 종류인가요?   \n",
              "4010                               가장 맛있는 피자 종류는 무엇일까요?   \n",
              "4011                                  가장 맛있는 피자는 무엇일까요?   \n",
              "4012                              가장 맛있는 해산물 요리는 무엇인가요?   \n",
              "4013                                   가장 매운 음식은 무엇인가요?   \n",
              "\n",
              "                                                      A  \n",
              "0     그런 일이 있었군요. 실수는 누구에게나 일어날 수 있는 일이에요. 중요한 건 그것을...  \n",
              "1     프로젝트를 혼자 맡는 것은 정말 큰 도전일 테지만, 동시에 많은 성장의 기회가 될 ...  \n",
              "2     첫 직장은 항상 긴장되고 설레는 시간이죠. 새로운 환경에서 적응하는 것은 어려운 일...  \n",
              "3     대단하시네요! 축하드립니다! 실력을 계속 향상시키고 성취를 이루는 건 정말 멋진 일...  \n",
              "4     축하해요! 새로운 노트북으로 더 많은 일들을 해나가실 거예요. 새로운 도구로 무엇을...  \n",
              "...                                                 ...  \n",
              "4009  가장 맛있는 파스타는 개인의 취향에 따라 다르지만, 많은 사람들이 즐기는 파스타 종...  \n",
              "4010  가장 맛있는 파스타는 개인의 취향에 따라 다르지만, \"마르게리타 피자\"는 많은 사람...  \n",
              "4011  가장 맛있는 파스타는 개인의 취향에 따라 다르지만, 소시지와 페퍼로니 토핑이 올려진...  \n",
              "4012  가장 맛있는 해산물 요리는 개인의 취향에 따라 다르지만, 간장게장, 매운 게장, 명...  \n",
              "4013  가장 매운 음식은 개인에 따라 다를 수 있지만, 전 세계적으로 알려진 매운 음식으로...  \n",
              "\n",
              "[4014 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2bcee9ba-48cd-4a11-b823-c2d5d3df96a4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>이번 프로젝트에서 발표를 하는데 내가 실수하는 바람에 우리 팀이 감점을 받았어. 너...</td>\n",
              "      <td>그런 일이 있었군요. 실수는 누구에게나 일어날 수 있는 일이에요. 중요한 건 그것을...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>회사에서 중요한 프로젝트를 혼자 하게 됐는데 솔직히 두렵고 무서워.</td>\n",
              "      <td>프로젝트를 혼자 맡는 것은 정말 큰 도전일 테지만, 동시에 많은 성장의 기회가 될 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>이번에 힘들게 들어간 첫 직장이거든. 첫 직장이라서 그런지 너무 긴장된다.</td>\n",
              "      <td>첫 직장은 항상 긴장되고 설레는 시간이죠. 새로운 환경에서 적응하는 것은 어려운 일...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>대회에 나갔는데 예전의 내 기록을 훨씬 갱신했어!</td>\n",
              "      <td>대단하시네요! 축하드립니다! 실력을 계속 향상시키고 성취를 이루는 건 정말 멋진 일...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>150만 원짜리 노트북을 샀는데 오늘 배송돼서 기분이 너무 좋아!</td>\n",
              "      <td>축하해요! 새로운 노트북으로 더 많은 일들을 해나가실 거예요. 새로운 도구로 무엇을...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4009</th>\n",
              "      <td>가장 맛있는 파스타는 어떤 종류인가요?</td>\n",
              "      <td>가장 맛있는 파스타는 개인의 취향에 따라 다르지만, 많은 사람들이 즐기는 파스타 종...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4010</th>\n",
              "      <td>가장 맛있는 피자 종류는 무엇일까요?</td>\n",
              "      <td>가장 맛있는 파스타는 개인의 취향에 따라 다르지만, \"마르게리타 피자\"는 많은 사람...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4011</th>\n",
              "      <td>가장 맛있는 피자는 무엇일까요?</td>\n",
              "      <td>가장 맛있는 파스타는 개인의 취향에 따라 다르지만, 소시지와 페퍼로니 토핑이 올려진...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4012</th>\n",
              "      <td>가장 맛있는 해산물 요리는 무엇인가요?</td>\n",
              "      <td>가장 맛있는 해산물 요리는 개인의 취향에 따라 다르지만, 간장게장, 매운 게장, 명...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4013</th>\n",
              "      <td>가장 매운 음식은 무엇인가요?</td>\n",
              "      <td>가장 매운 음식은 개인에 따라 다를 수 있지만, 전 세계적으로 알려진 매운 음식으로...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4014 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2bcee9ba-48cd-4a11-b823-c2d5d3df96a4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2bcee9ba-48cd-4a11-b823-c2d5d3df96a4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2bcee9ba-48cd-4a11-b823-c2d5d3df96a4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-061c64bd-226b-472d-97d6-7f0fb3a20fb8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-061c64bd-226b-472d-97d6-7f0fb3a20fb8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-061c64bd-226b-472d-97d6-7f0fb3a20fb8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_set",
              "summary": "{\n  \"name\": \"data_set\",\n  \"rows\": 4015,\n  \"fields\": [\n    {\n      \"column\": \"Q\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3680,\n        \"samples\": [\n          \"\\uc8fc\\ub9d0\\uc5d0 \\ub3c8\\ubd80\\ub9ac \\uba39\\uc5c8\\ub294\\ub370 \\uace0\\uae30\\uc640 \\ubc25\\uc774 \\uc798 \\uc5b4\\uc6b8\\ub838\\uc5b4.\",\n          \"\\uadf8 \\uc0ac\\ub78c\\uc5d0\\uac8c \\ub0b4 \\uac10\\uc815\\uc744 \\ud45c\\ud604\\ud558\\ub294 \\uac8c \\ub108\\ubb34 \\ub450\\ub824\\uc6cc.\",\n          \"\\uace8\\ud504 \\ub300\\ud68c \\uc900\\ube44 \\uc5f4\\uc2ec\\ud788 \\ud558\\uace0 \\uc788\\uc5b4. \\uc774\\ubc88\\uc5d0\\ub294 \\uc88b\\uc740 \\uc131\\uc801 \\ub0b4\\uace0 \\uc2f6\\uc5b4.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"A\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3732,\n        \"samples\": [\n          \"\\uce5c\\ud574\\uc9c0\\uace0 \\uc2f6\\ub2e4\\uba74 \\uc790\\uc8fc \\ub300\\ud654\\ub97c \\uc2dc\\ub3c4\\ud558\\uace0, \\uacf5\\ud1b5\\uc758 \\uad00\\uc2ec\\uc0ac\\ub97c \\ucc3e\\uc544\\ubcf4\\uc138\\uc694. \\uc791\\uc740 \\uc120\\ubb3c\\uc774\\ub098 \\uce6d\\ucc2c\\uc73c\\ub85c \\uc790\\uc2e0\\uc758 \\uac10\\uc815\\uc744 \\uc870\\uae08\\uc529 \\ud45c\\ud604\\ud574\\ubcf4\\uc138\\uc694.\",\n          \"\\ub124, \\uc774\\ubc88 \\uc8fc\\ub9d0\\uc5d0 \\ud559\\uad50 \\ud589\\uc0ac\\uc5d0 \\ucc38\\uc5ec\\ud558\\uba74 \\uc88b\\uc744 \\uac83 \\uac19\\uc544\\uc694. \\uc815\\ub9d0 \\uc7ac\\ubbf8\\uc788\\uc744 \\uac83 \\uac19\\uc544\\uc694. \\ud568\\uaed8 \\uac00\\uc694!\",\n          \"\\ud574\\uc0b0\\ubb3c \\ud30c\\uc2a4\\ud0c0\\ub3c4 \\uc2e0\\uc120\\ud558\\uace0 \\ub9db\\uc788\\uc8e0! \\ub2e4\\uc74c\\uc5d0\\ub3c4 \\uc990\\uac70\\uc6b4 \\uc2dd\\uc0ac \\ub418\\uc138\\uc694.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 최대 토큰 수 설정을 위한 함수 작성"
      ],
      "metadata": {
        "id": "OklvlfTkeaOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 문장을 토큰화하고 가장 긴 시퀀스 길이를 찾는 함수\n",
        "def find_max_len(dataset, tokenizer):\n",
        "    max_len = 0\n",
        "    for idx, row in dataset.iterrows():\n",
        "        q = row['Q']\n",
        "        a = row['A']\n",
        "\n",
        "        # 질문과 답변을 토큰화\n",
        "        q_toked = tokenizer.tokenize(q)\n",
        "        a_toked = tokenizer.tokenize(a)\n",
        "\n",
        "        # 토큰화된 질문과 답변의 길이 합산\n",
        "        total_len = len(q_toked) + len(a_toked)\n",
        "\n",
        "        # 최대 길이 갱신\n",
        "        if total_len > max_len:\n",
        "            max_len = total_len\n",
        "\n",
        "    return max_len\n",
        "\n",
        "# 데이터셋의 최대 토큰 길이 찾기\n",
        "max_len = find_max_len(data_set, tokenizer)\n",
        "print(f\"Max token length in the dataset: {max_len}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ArX4g4HV00U",
        "outputId": "ba4f169a-50f9-437e-9106-c251bb327f6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max token length in the dataset: 121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터셋 정의"
      ],
      "metadata": {
        "id": "1XqwBwzwegT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 정의\n",
        "class ChatbotDataset(Dataset):\n",
        "    def __init__(self, chats, max_len=40):\n",
        "        self._data = chats\n",
        "        self.max_len = max_len\n",
        "        self.q_token = Q_TKN\n",
        "        self.a_token = A_TKN\n",
        "        self.sent_token = SENT\n",
        "        self.eos = EOS\n",
        "        self.mask = MASK\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):  # ChatbotDataset의 길이를 리턴.\n",
        "        return len(self._data)\n",
        "\n",
        "    def __getitem__(self, idx):  # 로드한 ChatbotDataset을 차례차례 DataLoader로 넘겨주는 메서드\n",
        "        turn = self._data.iloc[idx]\n",
        "        q = turn[\"Q\"]  # 질문을 가져온다.\n",
        "\n",
        "        a = turn[\"A\"]  # 답변을 가져온다.\n",
        "\n",
        "        q_toked = self.tokenizer.tokenize(self.q_token + q + self.sent_token)\n",
        "        q_len = len(q_toked)\n",
        "\n",
        "        a_toked = self.tokenizer.tokenize(self.a_token + a + self.eos)\n",
        "        a_len = len(a_toked)\n",
        "\n",
        "        # 질문의 길이가 최대길이보다 크면\n",
        "        if q_len > self.max_len:\n",
        "            q_toked = q_toked[-(self.max_len // 2):]  # 질문길이를 최대길이의 반으로\n",
        "            q_len = len(q_toked)\n",
        "\n",
        "        # 질문의 길이 + 답변의 길이가 최대길이보다 크면\n",
        "        if q_len + a_len > self.max_len:\n",
        "            a_len = self.max_len - q_len\n",
        "            a_toked = a_toked[:a_len]\n",
        "            a_len = len(a_toked)\n",
        "\n",
        "        # 답변 labels = [mask, mask, ..., mask, ..., <bos>, ...답변..., <eos>, <pad> ...]\n",
        "        labels = [self.mask, ] * q_len + a_toked[1:]\n",
        "\n",
        "        # mask = 질문길이 0 + 답변길이 1 + 나머지 0\n",
        "        mask = [0] * q_len + [1] * a_len + [0] * (self.max_len - q_len - a_len)\n",
        "        # 답변 labels를 index로 만든다.\n",
        "        labels_ids = self.tokenizer.convert_tokens_to_ids(labels)\n",
        "        labels_ids += [self.tokenizer.pad_token_id] * (self.max_len - len(labels_ids))\n",
        "\n",
        "        #질문 + 답변을 index로 만든다.\n",
        "        token_ids = self.tokenizer.convert_tokens_to_ids(q_toked + a_toked)\n",
        "        token_ids += [self.tokenizer.pad_token_id] * (self.max_len - len(token_ids))\n",
        "\n",
        "        # attention mask 생성\n",
        "        attention_mask = [1] * (q_len + a_len) + [0] * (self.max_len - q_len - a_len)\n",
        "\n",
        "        # 질문 + 답변, 마스크, 답변, attention mask\n",
        "        return (token_ids, np.array(mask), labels_ids, attention_mask)"
      ],
      "metadata": {
        "id": "dTmaJURdMMcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 정의"
      ],
      "metadata": {
        "id": "OuSqUeLTelsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch(batch):\n",
        "    data = [item[0] for item in batch]\n",
        "    mask = [item[1] for item in batch]\n",
        "    label = [item[2] for item in batch]\n",
        "    attention_mask = [item[3] for item in batch]\n",
        "    return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label), torch.LongTensor(attention_mask)"
      ],
      "metadata": {
        "id": "QFw3NlY5WB0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = ChatbotDataset(data_set, max_len=max_len)\n",
        "train_dataloader = DataLoader(\n",
        "    train_set,\n",
        "    batch_size=32,  # 배치 크기 줄이기\n",
        "    num_workers=2,  # 윈도우->0 / 리눅스->2\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_batch,\n",
        ")\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJp4713TZA79",
        "outputId": "8d8c6910-b26c-4dc5-df0e-adbac8f43a00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(51200, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=51200, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 학습"
      ],
      "metadata": {
        "id": "e_-BlFL4eog7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler()  # Mixed precision을 위한 GradScaler\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    dataloader = tqdm(train_dataloader, desc=f\"Epoch {epoch}\")\n",
        "    model.train()\n",
        "    for batch_idx, samples in enumerate(dataloader):\n",
        "        # Gradient 0 으로 초기화\n",
        "        optimizer.zero_grad()\n",
        "        token_ids, mask, label, attention_mask = samples\n",
        "\n",
        "        # 데이터 타입 확인 및 GPU로 이동\n",
        "        token_ids, mask, label, attention_mask = token_ids.to(device), mask.to(device), label.to(device), attention_mask.to(device)\n",
        "\n",
        "        with torch.cuda.amp.autocast():  # Mixed precision 사용\n",
        "            out = model(token_ids, attention_mask=attention_mask)\n",
        "            out = out.logits\n",
        "            # 마스크 3D로 확장 및 출력 필터링\n",
        "            mask_3d = mask.unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2], dim=2)\n",
        "            mask_out = torch.where(mask_3d == 1, out, Sneg*torch.ones_like(out))\n",
        "\n",
        "            # 라벨 값이 클래스 개수 범위 내에 있는지 확인\n",
        "            assert label.max().item() < model.config.vocab_size, \"라벨 값이 클래스 개수보다 큽니다.\"\n",
        "\n",
        "            loss = criterion(mask_out.transpose(2, 1), label)\n",
        "            avg_loss = loss.sum() / mask.sum()\n",
        "\n",
        "        scaler.scale(avg_loss).backward()  # Mixed precision을 위한 gradient scaling\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        # GPU 메모리 정리\n",
        "        del token_ids, mask, label, attention_mask, out, mask_3d, mask_out, loss, avg_loss\n",
        "        torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99NDp48QZV2w",
        "outputId": "e6a35ecb-4769-43ab-a6f4-68692c56b585"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 0:   0%|          | 0/126 [00:00<?, ?it/s]<ipython-input-9-3fe971c8e99f>:6: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label), torch.LongTensor(attention_mask)\n",
            "<ipython-input-9-3fe971c8e99f>:6: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label), torch.LongTensor(attention_mask)\n",
            "Epoch 0: 100%|██████████| 126/126 [00:57<00:00,  2.18it/s]\n",
            "Epoch 1:   0%|          | 0/126 [00:00<?, ?it/s]<ipython-input-9-3fe971c8e99f>:6: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label), torch.LongTensor(attention_mask)\n",
            "<ipython-input-9-3fe971c8e99f>:6: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label), torch.LongTensor(attention_mask)\n",
            "Epoch 1: 100%|██████████| 126/126 [00:56<00:00,  2.24it/s]\n",
            "Epoch 2:   0%|          | 0/126 [00:00<?, ?it/s]<ipython-input-9-3fe971c8e99f>:6: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label), torch.LongTensor(attention_mask)\n",
            "<ipython-input-9-3fe971c8e99f>:6: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label), torch.LongTensor(attention_mask)\n",
            "Epoch 2: 100%|██████████| 126/126 [00:56<00:00,  2.23it/s]\n",
            "Epoch 3:   0%|          | 0/126 [00:00<?, ?it/s]<ipython-input-9-3fe971c8e99f>:6: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label), torch.LongTensor(attention_mask)\n",
            "<ipython-input-9-3fe971c8e99f>:6: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label), torch.LongTensor(attention_mask)\n",
            "Epoch 3: 100%|██████████| 126/126 [00:56<00:00,  2.23it/s]\n",
            "Epoch 4:   0%|          | 0/126 [00:00<?, ?it/s]<ipython-input-9-3fe971c8e99f>:6: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label), torch.LongTensor(attention_mask)\n",
            "<ipython-input-9-3fe971c8e99f>:6: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label), torch.LongTensor(attention_mask)\n",
            "Epoch 4: 100%|██████████| 126/126 [00:56<00:00,  2.22it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 테스트 (창의적 답변 생성)"
      ],
      "metadata": {
        "id": "CO-x3Dj5erL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "# 답변 생성 함수\n",
        "def sample_sequence(model, tokenizer, q, max_len=40, temperature=1.0, top_k=50, top_p=0.9):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        a = \"\"\n",
        "        for _ in range(max_len):\n",
        "            input_ids = torch.LongTensor(\n",
        "                tokenizer.encode(Q_TKN + q + SENT + A_TKN + a)\n",
        "            ).unsqueeze(dim=0).to(device)\n",
        "            pred = model(input_ids)\n",
        "            logits = pred.logits[:, -1, :] / temperature\n",
        "            filtered_logits = top_k_top_p_filtering(logits, top_k=top_k, top_p=top_p)\n",
        "            probabilities = torch.nn.functional.softmax(filtered_logits, dim=-1)\n",
        "            gen_id = torch.multinomial(probabilities, num_samples=1).item()\n",
        "            if gen_id >= tokenizer.vocab_size:\n",
        "                print(f\"Invalid token ID: {gen_id}\")\n",
        "                break\n",
        "            gen = tokenizer.convert_ids_to_tokens([gen_id])[0]\n",
        "            if gen == EOS:\n",
        "                break\n",
        "            a += gen.replace(\"▁\", \" \")\n",
        "        return a.strip()\n",
        "\n",
        "# logits를 필터링 하여 top-k 및 top-p 샘플링을 적용\n",
        "# top_k : 확률이 높은 상위 k개의 토큰 중에서 샘플링.\n",
        "# top_p : 누적 확률이 p 이하가 되는 상위 토큰들 중에서 샘플링\n",
        "def top_k_top_p_filtering(logits, top_k=0, top_p=0.0, filter_value=-float('Inf')):\n",
        "    # top_k 필터링\n",
        "    if top_k > 0:\n",
        "        top_k = min(top_k, logits.size(-1))\n",
        "        indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n",
        "        logits[indices_to_remove] = filter_value\n",
        "    # top_p 필터링\n",
        "    if top_p > 0.0:\n",
        "        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
        "        cumulative_probs = torch.cumsum(torch.nn.functional.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "        sorted_indices_to_remove = cumulative_probs > top_p\n",
        "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
        "        sorted_indices_to_remove[..., 0] = 0\n",
        "        indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
        "        if indices_to_remove.shape != logits.shape:\n",
        "                # print(f\"indices_to_remove shape mismatch: {indices_to_remove.shape} vs {logits.shape}\")\n",
        "                return logits\n",
        "        logits[indices_to_remove] = filter_value\n",
        "    return logits\n",
        "\n",
        "# 테스트\n",
        "with torch.no_grad():\n",
        "    while True:\n",
        "        q = input(\"user > \").strip()\n",
        "        if q == \"quit\":\n",
        "            break\n",
        "        response = sample_sequence(model, tokenizer, q, max_len=max_len, temperature=0.5, top_k=20, top_p=0.9) # temperature : 샘플링 온도로, 낮은 값은 덜 무작위 적이고, 높은 값은 더 무작위적인 결과를 만듬.\n",
        "        print(f\"Chatbot > {response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssrY4poMpX9J",
        "outputId": "a25a7d8f-fdb2-472c-e423-c97dc7cf64d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user > 안녕하세요\n",
            "Chatbot > 안녕하세요! 어떤 음식을 드셨나요?\n",
            "user > 음식은 안먹었고 커피 마시고 있어요\n",
            "Chatbot > 음식은 정말 중요하죠. 커피나 음료를 마시면서 기분 전환을 해보세요.\n",
            "user > 밥 중요하긴하죠. 하지만 지금은 새벽이라 아침먹기엔 멀었어요\n",
            "Chatbot > 새벽밥을 먹기엔 조금 더 여유로운 저녁이 필요해요. 신선한 야채와 함께 드시면 더욱 좋을 것 같아요.\n",
            "user > 새벽밥은 첨 들어보는데요?\n",
            "Chatbot > 새벽밥은 정말 맛있죠! 어떤 재료를 넣으셨어요?\n",
            "user > 그게 먼소리니...\n",
            "Chatbot > 먼소리니 정말 많이 듣고 계신 것 같아요. 그런 감정은 누구나 느낄 수 있어요. 천천히 자신을 돌아보는 시간이 필요해요.\n",
            "user > 배가 고파요\n",
            "Chatbot > 빠르게 준비할 수 있는 간단한 볶음밥이나 샌드위치를 만들어보세요. 간단한 볶음밥과 샌드위치는 간단하면서도 맛있죠! 맛있게 드세요.\n",
            "user > 저녁으로 뭘 먹어볼까요?\n",
            "Chatbot > 저녁으로 다양한 음식을 시도해보세요. 예를 들어, 신선한 샐러드를 만들어보는 것은 어떨까요?\n",
            "user > 제육은 어떤가요?\n",
            "Chatbot > 제육은 다양한 재료가 어우러져 맛있다고 알려져 있어요. 다양한 재료가 들어간 제육볶음은 정말 맛있죠.\n",
            "user > 아침으로 뭘 먹을까요?\n",
            "Chatbot > 아침 식사로 신선한 샐러드를 먹는 것은 어떨까요?\n",
            "user > 샐러드 괜찮네요\n",
            "Chatbot > 샐러드 괜찮네요! 샐러드는 어떤 종류로 드실 건가요?\n",
            "user > 방울토마토 샐러드 생각중이에요.\n",
            "Chatbot > 방울토마토 샐러드는 신선한 채소와 매콤한 소스가 어우러져 정말 맛있죠! 새로운 시도를 하셨다니 다행이에요.\n",
            "user > quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 다운로드"
      ],
      "metadata": {
        "id": "QQ5wqZKtTZkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from google.colab import files\n",
        "\n",
        "# 모델 가중치 저장\n",
        "torch.save(model.state_dict(), 'textGenerator_weights.pth')\n",
        "\n",
        "files.download('textGenerator_weights.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "KgIJl4v_MlxD",
        "outputId": "fd8772bd-6122-4b94-8561-f523bcd1e09d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ad4ffbbd-53b4-4688-a235-576f147c457a\", \"textGenerator_weights.pth\", 500689042)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 테스트 (일반 답변 생성)"
      ],
      "metadata": {
        "id": "TpPJIN68ewte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model.to(device)\n",
        "# # 테스트\n",
        "# with torch.no_grad():\n",
        "#   while True:\n",
        "#     q = input(\"user > \").strip()\n",
        "#     if q == \"quit\":\n",
        "#       break\n",
        "#     a = \"\"\n",
        "#     while 1:\n",
        "#       input_ids = torch.LongTensor(\n",
        "#           tokenizer.encode(Q_TKN + q + SENT + A_TKN + a)\n",
        "#       ).unsqueeze(dim=0).to(device)\n",
        "#       pred = model(input_ids)\n",
        "#       pred = pred.logits\n",
        "#       gen_id = torch.argmax(pred, dim=-1).squeeze().cpu().numpy().tolist()[-1]\n",
        "#       gen = tokenizer.convert_ids_to_tokens([gen_id])[0]\n",
        "#       if gen == EOS:\n",
        "#         break\n",
        "#       a += gen.replace(\"▁\", \" \")\n",
        "#     print(f\"Chatbot > {a.strip()}\")"
      ],
      "metadata": {
        "id": "pzbOPhE2en-i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}